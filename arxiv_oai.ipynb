{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"http://export.arxiv.org/oai2?verb=ListRecords&set=cs&from=2015-01-01&until=2015-01-31&metadataPrefix=arXiv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (64053137.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ans.content[]0\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ans.content[]0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D1606.07792v1%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=1606.07792v1&amp;start=0&amp;max_results=10</title>\\n  <id>http://arxiv.org/api/f9u/5ARzjjUTImuDusWYmLbsRFo</id>\\n  <updated>2023-07-25T00:00:00-04:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/1606.07792v1</id>\\n    <updated>2016-06-24T19:07:02Z</updated>\\n    <published>2016-06-24T19:07:02Z</published>\\n    <title>Wide &amp; Deep Learning for Recommender Systems</title>\\n    <summary>  Generalized linear models with nonlinear feature transformations are widely\\nused for large-scale regression and classification problems with sparse inputs.\\nMemorization of feature interactions through a wide set of cross-product\\nfeature transformations are effective and interpretable, while generalization\\nrequires more feature engineering effort. With less feature engineering, deep\\nneural networks can generalize better to unseen feature combinations through\\nlow-dimensional dense embeddings learned for the sparse features. However, deep\\nneural networks with embeddings can over-generalize and recommend less relevant\\nitems when the user-item interactions are sparse and high-rank. In this paper,\\nwe present Wide &amp; Deep learning---jointly trained wide linear models and deep\\nneural networks---to combine the benefits of memorization and generalization\\nfor recommender systems. We productionized and evaluated the system on Google\\nPlay, a commercial mobile app store with over one billion active users and over\\none million apps. Online experiment results show that Wide &amp; Deep significantly\\nincreased app acquisitions compared with wide-only and deep-only models. We\\nhave also open-sourced our implementation in TensorFlow.\\n</summary>\\n    <author>\\n      <name>Heng-Tze Cheng</name>\\n    </author>\\n    <author>\\n      <name>Levent Koc</name>\\n    </author>\\n    <author>\\n      <name>Jeremiah Harmsen</name>\\n    </author>\\n    <author>\\n      <name>Tal Shaked</name>\\n    </author>\\n    <author>\\n      <name>Tushar Chandra</name>\\n    </author>\\n    <author>\\n      <name>Hrishi Aradhye</name>\\n    </author>\\n    <author>\\n      <name>Glen Anderson</name>\\n    </author>\\n    <author>\\n      <name>Greg Corrado</name>\\n    </author>\\n    <author>\\n      <name>Wei Chai</name>\\n    </author>\\n    <author>\\n      <name>Mustafa Ispir</name>\\n    </author>\\n    <author>\\n      <name>Rohan Anil</name>\\n    </author>\\n    <author>\\n      <name>Zakaria Haque</name>\\n    </author>\\n    <author>\\n      <name>Lichan Hong</name>\\n    </author>\\n    <author>\\n      <name>Vihan Jain</name>\\n    </author>\\n    <author>\\n      <name>Xiaobing Liu</name>\\n    </author>\\n    <author>\\n      <name>Hemal Shah</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1606.07792v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1606.07792v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as libreq\n",
    "with libreq.urlopen('http://export.arxiv.org/api/query?id_list=1606.07792v1') as url:\n",
    "    r = url.read()\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D1606.07792v1%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=1606.07792v1&amp;start=0&amp;max_results=10</title>\\n  <id>http://arxiv.org/api/f9u/5ARzjjUTImuDusWYmLbsRFo</id>\\n  <updated>2023-07-25T00:00:00-04:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/1606.07792v1</id>\\n    <updated>2016-06-24T19:07:02Z</updated>\\n    <published>2016-06-24T19:07:02Z</published>\\n    <title>Wide &amp; Deep Learning for Recommender Systems</title>\\n    <summary>  Generalized linear models with nonlinear feature transformations are widely\\nused for large-scale regression and classification problems with sparse inputs.\\nMemorization of feature interactions through a wide set of cross-product\\nfeature transformations are effective and interpretable, while generalization\\nrequires more feature engineering effort. With less feature engineering, deep\\nneural networks can generalize better to unseen feature combinations through\\nlow-dimensional dense embeddings learned for the sparse features. However, deep\\nneural networks with embeddings can over-generalize and recommend less relevant\\nitems when the user-item interactions are sparse and high-rank. In this paper,\\nwe present Wide &amp; Deep learning---jointly trained wide linear models and deep\\nneural networks---to combine the benefits of memorization and generalization\\nfor recommender systems. We productionized and evaluated the system on Google\\nPlay, a commercial mobile app store with over one billion active users and over\\none million apps. Online experiment results show that Wide &amp; Deep significantly\\nincreased app acquisitions compared with wide-only and deep-only models. We\\nhave also open-sourced our implementation in TensorFlow.\\n</summary>\\n    <author>\\n      <name>Heng-Tze Cheng</name>\\n    </author>\\n    <author>\\n      <name>Levent Koc</name>\\n    </author>\\n    <author>\\n      <name>Jeremiah Harmsen</name>\\n    </author>\\n    <author>\\n      <name>Tal Shaked</name>\\n    </author>\\n    <author>\\n      <name>Tushar Chandra</name>\\n    </author>\\n    <author>\\n      <name>Hrishi Aradhye</name>\\n    </author>\\n    <author>\\n      <name>Glen Anderson</name>\\n    </author>\\n    <author>\\n      <name>Greg Corrado</name>\\n    </author>\\n    <author>\\n      <name>Wei Chai</name>\\n    </author>\\n    <author>\\n      <name>Mustafa Ispir</name>\\n    </author>\\n    <author>\\n      <name>Rohan Anil</name>\\n    </author>\\n    <author>\\n      <name>Zakaria Haque</name>\\n    </author>\\n    <author>\\n      <name>Lichan Hong</name>\\n    </author>\\n    <author>\\n      <name>Vihan Jain</name>\\n    </author>\\n    <author>\\n      <name>Xiaobing Liu</name>\\n    </author>\\n    <author>\\n      <name>Hemal Shah</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/1606.07792v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1606.07792v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with libreq.urlopen('http://export.arxiv.org/api/query?id_list=1606.07792v1') as url:\n",
    "    r = url.read()\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D1606.07793v1%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=1606.07793v1&amp;start=0&amp;max_results=10</title>\\n  <id>http://arxiv.org/api/ujbODOzf6aECZpm26/j5S8btMts</id>\\n  <updated>2023-07-25T00:00:00-04:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/1606.07793v1</id>\\n    <updated>2016-06-24T19:16:06Z</updated>\\n    <published>2016-06-24T19:16:06Z</published>\\n    <title>The Higgs singlet extension at LHC Run 2</title>\\n    <summary>  We discuss the current status of theoretical and experimental constraints on\\nthe real Higgs singlet extension of the Standard Model. For the second neutral\\n(non-standard) Higgs boson the mass range up to 1 TeV accessible at past and\\ncurrent collider experiments is considered. We furthermore discuss electroweak\\ncorrections to the H to hh partial decay width within this model.\\n</summary>\\n    <author>\\n      <name>Guillaume Chalons</name>\\n    </author>\\n    <author>\\n      <name>David Lopez-Val</name>\\n    </author>\\n    <author>\\n      <name>Tania Robens</name>\\n    </author>\\n    <author>\\n      <name>Tim Stefaniak</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5 pages, 3 figures, Proceedings of the XXIV International Workshop on\\n  Deep-Inelastic Scattering and Related Subjects</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/1606.07793v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1606.07793v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"hep-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"hep-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with libreq.urlopen('http://export.arxiv.org/api/query?id_list=1606.07793v1') as url:\n",
    "    r = url.read()\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
