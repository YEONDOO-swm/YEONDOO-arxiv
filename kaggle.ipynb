{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.concurrent import process_map  # or thread_map\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from multiprocessing import Manager\n",
    "from functools import partial\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/soma4/.kaggle/kaggle.json'\n",
      "Downloading arxiv.zip to /home/soma4/YEONDOO-arxiv-with-version/YEONDOO-arxiv\n",
      "100%|██████████████████████████████████████| 1.17G/1.17G [01:53<00:00, 11.1MB/s]\n",
      "100%|██████████████████████████████████████| 1.17G/1.17G [01:53<00:00, 11.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# !kaggle datasets download -d Cornell-University/arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of dicts and convert into a pandas df.\n",
    "arxiv_data = []\n",
    "for line in open('../arxiv-metadata-oai-snapshot.json', 'r'):\n",
    "    arxiv_data.append(json.loads(line))\n",
    "df = pd.DataFrame.from_records(arxiv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['categories'].str.contains('cs', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>737196</th>\n",
       "      <td>1605.09081</td>\n",
       "      <td>Jayanth Koushik</td>\n",
       "      <td>Jayanth Koushik</td>\n",
       "      <td>Understanding Convolutional Neural Networks</td>\n",
       "      <td>Statistical Machine Learning Course Project at...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>stat.OT</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Convoulutional Neural Networks (CNNs) exhibi...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 30 May 201...</td>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>[[Koushik, Jayanth, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id        submitter          authors  \\\n",
       "737196  1605.09081  Jayanth Koushik  Jayanth Koushik   \n",
       "\n",
       "                                              title  \\\n",
       "737196  Understanding Convolutional Neural Networks   \n",
       "\n",
       "                                                 comments journal-ref   doi  \\\n",
       "737196  Statistical Machine Learning Course Project at...        None  None   \n",
       "\n",
       "       report-no categories  \\\n",
       "737196      None    stat.OT   \n",
       "\n",
       "                                                  license  \\\n",
       "737196  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                                 abstract  \\\n",
       "737196    Convoulutional Neural Networks (CNNs) exhibi...   \n",
       "\n",
       "                                                 versions update_date  \\\n",
       "737196  [{'version': 'v1', 'created': 'Mon, 30 May 201...  2016-10-30   \n",
       "\n",
       "                authors_parsed  \n",
       "737196  [[Koushik, Jayanth, ]]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"id\"]==\"1605.09081\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"id\"]==]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3264255406434721"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered)/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749538"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del arxiv_data\n",
    "gc.collect()\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir=\"/home/soma4/YEONDOO-arxiv-with-version/YEONDOO-arxiv/data/\"\n",
    "year=\"14\"\n",
    "month=\"01\"\n",
    "path_data=os.path.join(basedir,year,month)\n",
    "id_list=os.listdir(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list=[id.split('v')[0] for id in os.listdir(path_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1401.4606'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cs.AI', 'cs.LO']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['id']==id_list[2]]['categories'].item().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493844</th>\n",
       "      <td>1401.4613</td>\n",
       "      <td>Peter Jeavons</td>\n",
       "      <td>Peter Jeavons, Justyna Petke</td>\n",
       "      <td>Local Consistency and SAT-Solvers</td>\n",
       "      <td>None</td>\n",
       "      <td>Journal Of Artificial Intelligence Research, V...</td>\n",
       "      <td>10.1613/jair.3531</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI cs.LO</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>Local consistency techniques such as k-consi...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 18 Jan 201...</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>[[Jeavons, Peter, ], [Petke, Justyna, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      submitter                       authors  \\\n",
       "493844  1401.4613  Peter Jeavons  Peter Jeavons, Justyna Petke   \n",
       "\n",
       "                                    title comments  \\\n",
       "493844  Local Consistency and SAT-Solvers     None   \n",
       "\n",
       "                                              journal-ref                doi  \\\n",
       "493844  Journal Of Artificial Intelligence Research, V...  10.1613/jair.3531   \n",
       "\n",
       "       report-no   categories  \\\n",
       "493844      None  cs.AI cs.LO   \n",
       "\n",
       "                                                  license  \\\n",
       "493844  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "\n",
       "                                                 abstract  \\\n",
       "493844    Local consistency techniques such as k-consi...   \n",
       "\n",
       "                                                 versions update_date  \\\n",
       "493844  [{'version': 'v1', 'created': 'Sat, 18 Jan 201...  2014-01-21   \n",
       "\n",
       "                                  authors_parsed  \n",
       "493844  [[Jeavons, Peter, ], [Petke, Justyna, ]]  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['id']==id_list[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=\"1401.0001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493837    2014-01-21\n",
       "Name: update_date, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['id']==id]['update_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "papper_id=id\n",
    "published=df[df['id']==id]['update_date']\n",
    "title=df[df['id']==id].title.item()\n",
    "\n",
    "authors_replaced=df[df['id']==id].authors.item().replace('and',',').split(',')\n",
    "authors=authors_replaced.split(',')\n",
    "summary=df[df['id']==id].abstract.item()\n",
    "url=\"http://arxiv.org/abs/\"+id\n",
    "ref=df[df['id']==id]['journal-ref'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nils Bertschinger ',\n",
       " ' David H. Wolpert ',\n",
       " ' Eckehard Olbrich ',\n",
       " '\\n  Juergen Jost']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['id']==id].authors.item().replace('and',',').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nils Bertschinger and David H. Wolpert and Eckehard Olbrich and\\n  Juergen Jost'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['id']==id].authors.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-21'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published=df[df['id']==id]['update_date'].item()\n",
    "published\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1401.4606'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_list[0][:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Wrapper(shared_list,doc_file_name):\n",
    "    \n",
    "    id=doc_file_name.split('v')[0]\n",
    "    file_path=os.path.join(basedir,year,month,doc_file_name)\n",
    "    try:\n",
    "        with fitz.open(file_path) as doc_file:\n",
    "            text: str = \"\".join(page.get_text() for page in doc_file)\n",
    "    except:\n",
    "        print(file_path)\n",
    "        return\n",
    "    result=df_filtered[df_filtered[\"id\"]==id]\n",
    "\n",
    "    metadata = {\n",
    "        \"Published\": str(result[\"update_date\"].item()),\n",
    "        \"Title\": result.title.item(),\n",
    "        \"Authors\": result.authors.item().replace('and',',').split(','),\n",
    "        \"Summary\": result.abstract.item(),\n",
    "\n",
    "        \"paper_id\": id,\n",
    "\n",
    "        \"journal_ref\": result['journal-ref'].item(),\n",
    "        \n",
    "        \"categories\": result.categories.item().split(' '),\n",
    "        \"source\": \"http://arxiv.org/abs/\"+id,\n",
    "    }\n",
    "    doc = Document(\n",
    "        page_content=text, metadata=metadata\n",
    "    )\n",
    "    shared_list.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Wrapper2(shared_list,inputs):\n",
    "    \n",
    "    doc_file_name = inputs[0]\n",
    "    result=inputs[1]\n",
    "    id=doc_file_name.split('v')[0]\n",
    "    file_path=os.path.join(basedir,year,month,doc_file_name)\n",
    "    with fitz.open(file_path) as doc_file:\n",
    "        text: str = \"\".join(page.get_text() for page in doc_file)\n",
    "    \n",
    "    # result=df[df[\"id\"]==id]\n",
    "\n",
    "    metadata = {\n",
    "        \"Published\": str(result[\"update_date\"].item()),\n",
    "        \"Title\": result.title.item(),\n",
    "        \"Authors\": result.authors.item().replace('and',',').split(','),\n",
    "        \"Summary\": result.abstract.item(),\n",
    "\n",
    "        \"paper_id\": id,\n",
    "\n",
    "        \"journal_ref\": result['journal-ref'].item(),\n",
    "        \n",
    "        \"categories\": result.categories,\n",
    "        \"source\": \"http://arxiv.org/abs/\"+id,\n",
    "    }\n",
    "    doc = Document(\n",
    "        page_content=text, metadata=metadata\n",
    "    )\n",
    "    shared_list.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir=\"/home/soma4/YEONDOO-arxiv-with-version/YEONDOO-arxiv/data/\"\n",
    "year=\"14\"\n",
    "month=\"01\"\n",
    "path_data=os.path.join(basedir,year,month)\n",
    "pdf_list=os.listdir(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunksize=2\n",
    "\n",
    "manager = Manager()\n",
    "shared_list = manager.list()\n",
    "process_map(partial(Wrapper, shared_list),pdf_list,max_workers=5,chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Journal of Artiﬁcial Intelligence Research 43 (2012) 329-351\\nSubmitted 11/11; published 03/12\\nLocal Consistency and SAT-Solvers\\nPeter Jeavons\\nPeter.Jeavons@cs.ox.ac.uk\\nJustyna Petke\\nJustyna.Petke@cs.ox.ac.uk\\nDepartment of Computer Science, University of Oxford\\nWolfson Building, Parks Road, Oxford, OX1 3QD, UK\\nAbstract\\nLocal consistency techniques such as k-consistency are a key component of specialised\\nsolvers for constraint satisfaction problems.\\nIn this paper we show that the power of\\nusing k-consistency techniques on a constraint satisfaction problem is precisely captured by\\nusing a particular inference rule, which we call negative-hyper-resolution, on the standard\\ndirect encoding of the problem into Boolean clauses. We also show that current clause-\\nlearning SAT-solvers will discover in expected polynomial time any inconsistency that can\\nbe deduced from a given set of clauses using negative-hyper-resolvents of a ﬁxed size. We\\ncombine these two results to show that, without being explicitly designed to do so, current\\nclause-learning SAT-solvers eﬃciently simulate k-consistency techniques, for all ﬁxed values\\nof k. We then give some experimental results to show that this feature allows clause-learning\\nSAT-solvers to eﬃciently solve certain families of constraint problems which are challenging\\nfor conventional constraint-programming solvers.\\n1. Introduction\\nOne of the oldest and most central ideas in constraint programming, going right back to\\nMontanari’s original paper in 1974, is the idea of using local consistency techniques to prune\\nthe search space (Bessi`ere, 2006). The idea of arc-consistency was introduced by Mackworth\\n(1977), and generalised to k-consistency by Freuder (1978).\\nModern constraint solvers\\ngenerally employ specialised propagators to prune the domains of variables to achieve some\\nform of generalised arc-consistency, but typically do not attempt to enforce higher levels of\\nconsistency, such as path-consistency.\\nBy contrast, the software tools developed to solve propositional satisﬁability problems,\\nknown as SAT-solvers, generally use logical inference techniques, such as unit propagation\\nand clause-learning, to prune the search space.\\nOne of the most surprising empirical ﬁndings of the last few years has been the remark-\\nably good performance of general SAT-solvers in solving constraint satisfaction problems.\\nTo apply such tools to a constraint satisfaction problem one ﬁrst has to translate the in-\\nstance into a set of clauses using some form of Boolean encoding (Tamura, Taga, Kitagawa,\\n& Banbara, 2009; Walsh, 2000).\\nSuch encoding techniques tend to obscure the struc-\\nture of the original problem, and may introduce a very large number of Boolean variables\\nand clauses to encode quite easily-stated constraints. Nevertheless, in quite a few cases,\\nsuch approaches have out-performed more traditional constraint-solving tools (van Dongen,\\nLecoutre, & Roussel, 2008, 2009; Petke & Jeavons, 2009).\\nc⃝2012 AI Access Foundation. All rights reserved.\\nJeavons & Petke\\nIn this paper we draw on a number of recent analytical approaches to try to account\\nfor the good performance of general SAT-solvers on many forms of constraint problems.\\nBuilding on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau\\n(2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency\\ntechniques in a constraint problem is precisely captured by using a single inference rule in\\na standard Boolean encoding of that problem. We refer to this inference rule as negative-\\nhyper-resolution, and show that any conclusions deduced by enforcing k-consistency can be\\ndeduced by a sequence of negative-hyper-resolution inferences involving Boolean clauses in\\nthe original instance and negative-hyper-resolvents with at most k literals. Furthermore,\\nby using the approach of Atserias, Fichte, and Thurley (2011), and Pipatsrisawat and\\nDarwiche (2009), we show that current clause-learning SAT-solvers will mimic the eﬀect of\\nsuch deductions in polynomial expected time, even with a random branching strategy. Hence\\nwe show that, although they are not explicitly designed to do so, running a clause-learning\\nSAT-solver on a straightforward encoding of a constraint problem eﬃciently simulates the\\neﬀects of enforcing k-consistency for all values of k.\\n2. Preliminaries\\nIn this section we give some background and deﬁnitions that will be used throughout the\\nrest of the paper.\\n2.1 Constraint Satisfaction Problems and k-Consistency\\nDeﬁnition 1 An instance of the Constraint Satisfaction Problem (CSP) is speciﬁed\\nby a triple (V, D, C), where\\n• V is a ﬁnite set of variables;\\n• D = {Dv | v ∈ V } where each set Dv is the set of possible values for the variable v,\\ncalled the domain of v;\\n• C is a ﬁnite set of constraints. Each constraint in C is a pair (Ri, Si) where\\n– Si is an ordered list of mi variables, called the constraint scope;\\n– Ri is a relation over D of arity mi, called the constraint relation.\\nGiven any CSP instance (V, D, C), a partial assignment is a mapping f from some\\nsubset W of V to � Dv such that f(v) ∈ Dv for all v ∈ W. A partial assignment satisﬁes\\nthe constraints of the instance if, for all (R, (v1, v2, . . . , vm)) ∈ C such that vj ∈ W for\\nj = 1, 2, . . . , m, we have (f(v1), f(v2) . . . , f(vm)) ∈ R. A partial assignment that satisﬁes\\nthe constraints of an instance is called a partial solution1 to that instance.\\nThe set of\\nvariables on which a partial assignment f is deﬁned is called the domain of f, and denoted\\nDom(f).\\nA partial solution g extends a partial solution f if Dom(g) ⊇ Dom(f) and\\ng(v) = f(v) for all v ∈ Dom(f). A partial solution with domain V is called a solution.\\nOne way to derive new information about a CSP instance, which may help to determine\\nwhether or not it has a solution, is to use some form of constraint propagation to enforce\\n1. Note that not all partial solutions extend to solutions.\\n330\\nLocal Consistency and SAT-Solvers\\nsome level of local consistency (Bessi`ere, 2006). For example, it is possible to use the notion\\nof k-consistency, deﬁned below. We note that there are several diﬀerent but equivalent ways\\nto deﬁne and enforce k-consistency described in the literature (Bessi`ere, 2006; Cooper, 1989;\\nFreuder, 1978). Our presentation follows that of Atserias et al. (2007), which is inspired by\\nthe notion of existential k-pebble games introduced by Kolaitis and Vardi (2000).\\nDeﬁnition 2 (Atserias et al., 2007) For any CSP instance P, the k-consistency closure\\nof P is the set H of partial assignments which is obtained by the following algorithm:\\n1. Let H be the collection of all partial solutions f of P with |Dom(f)| ≤ k + 1;\\n2. For every f ∈ H with |Dom(f)| ≤ k and every variable v of P, if there is no g ∈ H\\nsuch that g extends f and v ∈ Dom(g), then remove f and all its extensions from H;\\n3. Repeat step 2 until H is unchanged.\\nNote that computing the k-consistency closure according to this deﬁnition corresponds\\nprecisely to enforcing strong (k+1)-consistency according to the deﬁnitions given by Bessi`ere\\n(2006), Cooper (1989), and Freuder (1978).\\nThroughout this paper, we shall assume that the domain of possible values for each\\nvariable in a CSP instance is ﬁnite. It is straightforward to show that for any ﬁxed k,\\nand any ﬁxed maximum domain size, the k-consistency closure of an instance P can be\\ncomputed in polynomial time (Atserias et al., 2007; Cooper, 1989).\\nNote that any solution to P must extend some element of the k-consistency closure of\\nP. Hence, if the k-consistency closure of P is empty, for some k, then P has no solutions.\\nThe converse is not true in general, but it holds for certain special cases, such as the class of\\ninstances whose structure has tree-width bounded by k (Atserias et al., 2007), or the class\\nof instances whose constraint relations are “0/1/all” relations, as deﬁned in Cooper, Cohen,\\nand Jeavons (1994), or “connected row-convex” relations, as deﬁned in Deville, Barette,\\nand Hentenryck (1997). For these special kinds of instances it is possible to determine in\\npolynomial time whether or not a solution exists simply by computing the k-consistency\\nclosure, for an appropriate choice of k.\\nMoreover, if a solution exists, then it can be\\nconstructed in polynomial time by selecting each variable in turn, assigning each possible\\nvalue, re-computing the k-consistency closure, and retaining an assignment that gives a\\nnon-empty result.\\nThe following result gives a useful condition for determining whether the k-consistency\\nclosure of a CSP instance is empty.\\nLemma 1 (Kolaitis & Vardi, 2000) The k-consistency closure of a CSP instance P is\\nnon-empty if and only if there exists a non-empty family H of partial solutions to P such\\nthat:\\n1. If f ∈ H, then |Dom(f)| ≤ k + 1;\\n2. If f ∈ H and f extends g, then g ∈ H;\\n3. If f ∈ H, |Dom(f)| ≤ k, and v /∈ Dom(f) is a variable of P, then there is some\\ng ∈ H such that g extends f and v ∈ Dom(g).\\nA set of partial solutions H satisfying the conditions described in Lemma 1 is sometimes\\ncalled a strategy for the instance P (Barto & Kozik, 2009; Kolaitis & Vardi, 2000).\\n331\\nJeavons & Petke\\n2.2 Encoding a CSP Instance as a Propositional Formula\\nOne possible approach to solving a CSP instance is to encode it as a propositional formula\\nover a suitable set of Boolean variables, and then use a program to decide the satisﬁability\\nof that formula. Many such programs, known as SAT-solvers, are now available and can\\noften eﬃciently handle problems with thousands, or sometimes even millions, of Boolean\\nvariables (Zhang & Malik, 2002).\\nSeveral diﬀerent ways of encoding a CSP instance as a propositional formula have been\\nproposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).\\nHere we consider one common family of encodings, known as sparse encodings (this term\\nwas introduced in Hoos, 1999). For any CSP instance P = (V, D, C), a sparse encoding\\nintroduces a set of Boolean variables of the form xvi for each v ∈ V and each i ∈ Dv. The\\nBoolean variable xvi is assigned True if and only if the original variable v is assigned the\\nvalue i. We will say that a partial assignment f falsiﬁes a clause C if C consists entirely of\\nliterals of the form ¬xvf(v), for variables v ∈ Dom(f). Otherwise, we will say that a partial\\nassignment f satisﬁes a clause C.\\nExample 1 Let P be a CSP instance such that V = {u, v, w}, Du = Dv = {0, 1}, Dw =\\n{0, 1, 2} and C contains a single ternary constraint with scope (u, v, w) specifying that\\nu ≤ v < w. A sparse encoding of P will introduce seven Boolean variables:\\nxu0, xu1, xv0, xv1, xw0, xw1, xw2.\\nSparse encodings usually contain certain clauses known as at-least-one and at-most-one\\nclauses, to ensure that each variable v is assigned a value, say i, and that no other value,\\nj ̸= i, is assigned to v. The at-least-one clauses are of the form �\\ni∈Dv xvi for each variable\\nv. The at-most-one clauses can be represented as a set of binary clauses ¬xvi ∨ ¬xvj for all\\ni, j ∈ Dv with i ̸= j.\\nExample 2 In the case of the CSP instance from Example 1 the at-least-one clauses are:\\nxu0 ∨ xu1, xv0 ∨ xv1, xw0 ∨ xw1 ∨ xw2\\nThe at-most-one clauses are:\\n¬xu0 ∨ ¬xu1, ¬xv0 ∨ ¬xv1, ¬xw0 ∨ ¬xw1, ¬xw0 ∨ ¬xw2, ¬xw1 ∨ ¬xw2\\nThe various diﬀerent sparse encodings diﬀer in the way they encode the constraints of a\\nCSP instance. Two methods are most commonly used. The ﬁrst one encodes the disallowed\\nvariable assignments - the so-called conﬂicts or no-goods. The direct encoding (Prestwich,\\n2009), for instance, generates a clause �\\nv∈S ¬xvf(v) for each partial assignment f that does\\nnot satisfy the constraint (R, S) ∈ C. Using the direct encoding, the ternary constraint\\nfrom Example 1 would be encoded by the following clauses:\\n¬xu0 ∨ ¬xv0 ∨ ¬xw0,\\n¬xu0 ∨ ¬xv1 ∨ ¬xw0,\\n¬xu0 ∨ ¬xv1 ∨ ¬xw1,\\n¬xu1 ∨ ¬xv0 ∨ ¬xw0,\\n332\\nLocal Consistency and SAT-Solvers\\n¬xu1 ∨ ¬xv0 ∨ ¬xw1,\\n¬xu1 ∨ ¬xv0 ∨ ¬xw2,\\n¬xu1 ∨ ¬xv1 ∨ ¬xw0,\\n¬xu1 ∨ ¬xv1 ∨ ¬xw1.\\nAnother way of translating constraints into clauses is to encode the allowed variable\\nassignments - the so-called supports. This has been used as the basis for an encoding of\\nbinary CSP instances, known as the support encoding (Gent, 2002), deﬁned as follows.\\nFor each pair of variables v, w in the scope of some constraint, and each value i ∈ Dv,\\nthe support encoding will contain the clause ¬xvi ∨ �\\nj∈A xwj, where A ⊆ Dw is the set of\\nvalues for the variable w which are compatible with the assignment v = i, according to the\\nconstraint.\\nNote that the support encoding is deﬁned for binary CSP instances only. However, some\\nnon-binary constraints can be decomposed into binary ones without introducing any new\\nvariables. For instance, the ternary constraint from Example 1 can be decomposed into two\\nbinary constraints specifying that u ≤ v and v < w. Using the support encoding, these\\nbinary constraints would then be represented by the following clauses:\\n¬xu0 ∨ xv0 ∨ xv1, ¬xu1 ∨ xv1, ¬xv0 ∨ xu0, ¬xv1 ∨ xu0 ∨ xu1,\\n¬xv0 ∨ xw1 ∨ xw2, ¬xv1 ∨ xw2, ¬xw0, ¬xw1 ∨ xv0, ¬xw2 ∨ xv0 ∨ xv1.\\n2.3 Inference Rules\\nGiven any set of clauses we can often deduce further clauses by applying certain inference\\nrules. For example, if we have two clauses of the form C1∨x and C2∨¬x, for some (possibly\\nempty) clauses C1, C2, and some variable x, then we can deduce the clause C1 ∨ C2. This\\nform of inference is known as propositional resolution; the resultant clause is called the\\nresolvent (Robinson, 1965).\\nIn the next section, we shall establish a close connection between the k-consistency\\nalgorithm and a form of inference called negative-hyper-resolution (B¨uning & Lettmann,\\n1999), which we deﬁne as follows:\\nDeﬁnition 3 If we have a collection of clauses of the form Ci ∨ ¬xi, for i = 1, 2, . . . , r,\\nand a clause C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr, where each xi is a Boolean variable, and C0 and\\neach Ci is a (possibly empty) disjunction of negative literals, then we can deduce the clause\\nC0 ∨ C1 ∨ · · · ∨ Cr.\\nWe call this form of inference negative-hyper-resolution and the resultant clause\\nC0 ∨ C1 ∨ · · · ∨ Cr the negative-hyper-resolvent.\\nIn the case where C0 is empty, the negative-hyper-resolution rule is equivalent to the\\nnogood resolution rule described by Hwang and Mitchell (2005) as well as the H5-k rule\\nintroduced by de Kleer (1989) and the nogood recording scheme described by Schiex and\\nVerfaillie (1993).\\nNote that the inference obtained by negative-hyper-resolution can also be obtained by a\\nsequence of standard resolution steps. However, the reason for introducing negative-hyper-\\nresolution is that it allows us to deduce the clauses we need in a single step without needing\\nto introduce intermediate clauses (which may contain up to r − 1 more literals than the\\n333\\nJeavons & Petke\\nnegative-hyper-resolvent). By restricting the size of the clauses we use in this way we are\\nable to obtain better performance bounds for SAT-solvers in the results below.\\nExample 3 Assume we have a collection of clauses of the form Ci∨¬xi, for i = 1, 2, . . . , r,\\nand a clause C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr, as speciﬁed in Deﬁnition 3, where each Ci = C0. The\\nnegative-hyper-resolvent of this set of clauses is C0.\\nThe clause C0 can also be obtained by a sequence of standard resolution steps, as follows.\\nFirst resolve C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr with C0 ∨ ¬xr to obtain C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr−1. Then\\nresolve this with the next clause, C0 ∨ ¬xr−1, and so on for the other clauses, until ﬁnally\\nwe obtain C0. However, in this case the intermediate clause C0∨x1∨x2∨· · ·∨xr−1 contains\\nr − 1 more literals than the negative-hyper-resolvent.\\nExample 4 Note that the no-good clauses in the direct encoding of a binary CSP instance\\ncan each be obtained by a single negative-hyper-resolution step from an appropriate support\\nclause in the support encoding together with an appropriate collection of at-most-one clauses.\\nLet A ⊆ Dw be the set of values for the variable w which are compatible with the assignment\\nv = i, then the support encoding will contain the clause C = ¬xvi ∨ �\\nj∈A xwj. If there are\\nany values k ∈ Dw which are incompatible with the assignment v = i, then we can form the\\nnegative-hyper-resolvent of C with the at-most-one clauses ¬xwk ∨ ¬xwj for each j ∈ A, to\\nobtain the corresponding no-good clause, ¬xvi ∨ ¬xwk.\\nA negative-hyper-resolution derivation of a clause C from a set of initial clauses Φ is\\na sequence of clauses C1, C2, . . . , Cm, where Cm = C and each Ci follows by the negative-\\nhyper-resolution rule from some collection of clauses, each of which is either contained in\\nΦ or else occurs earlier in the sequence. The width of this derivation is deﬁned to be the\\nmaximum size of any of the clauses Ci. If Cm is the empty clause, then we say that the\\nderivation is a negative-hyper-resolution refutation of Φ.\\n3. k-Consistency and Negative-Hyper-Resolution\\nIt has been pointed out by many authors that enforcing local consistency is a form of\\ninference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007;\\nBessi`ere, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). The precise strength of the\\nstandard resolution inference rule on the direct encoding of a CSP instance was considered\\nin the work of Walsh (2000), where it was shown that unit resolution (where one of the\\nclauses being resolved consists of a single literal), corresponds to enforcing a weak form of\\nlocal consistency known as forward checking. Hwang and Mitchell (2005) pointed out that\\nthe standard resolution rule with no restriction on clause length is able to simulate all the\\ninferences made by a k-consistency algorithm. Atserias and Dalmau (2008) showed that\\nthe standard resolution rule restricted to clauses with at most k literals, known as the k-\\nresolution rule, can be characterised in terms of the Boolean existential (k+1)-pebble game.\\nIt follows that on CSP instances with Boolean domains this form of inference corresponds\\nto enforcing k-consistency. An alternative proof that k-resolution achieves k-consistency for\\ninstances with Boolean domains is given in the book by Hooker (2006, Thm. 3.22).\\nHere we extend these results a little, to show that for CSP instances with arbitrary\\nﬁnite domains, applying the negative-hyper-resolution rule on the direct encoding to obtain\\n334\\nLocal Consistency and SAT-Solvers\\nclauses with at most k literals corresponds precisely to enforcing k-consistency. A similar\\nrelationship was stated in the work of de Kleer (1989), but a complete proof was not given.\\nNote that the bound, k, that we impose on the size of the negative-hyper-resolvents,\\nis independent of the domain size. In other words, using this inference rule we only need\\nto consider inferred clauses of size at most k, even though we make use of clauses in the\\nencoding whose size is equal to the domain size, which may be arbitrarily large.\\nTheorem 1 The k-consistency closure of a CSP instance P is empty if and only if its direct\\nencoding as a set of clauses has a negative-hyper-resolution refutation of width at most k.\\nThe proof is broken down into two lemmas inspired by Lemmas 2 and 3 in the work\\nof Atserias and Dalmau (2008).\\nLemma 2 Let P be a CSP instance, and let Φ be its direct encoding as a set of clauses.\\nIf Φ has no negative-hyper-resolution refutation of width k or less, then the k-consistency\\nclosure of P is non-empty.\\nProof.\\nLet V be the set of variables of P, where each v ∈ V has domain Dv, and let\\nX = {xvi | v ∈ V, i ∈ Dv} be the corresponding set of Boolean variables in Φ. Let Γ be the\\nset of all clauses having a negative-hyper-resolution derivation from Φ of width at most k.\\nBy the deﬁnition of negative-hyper-resolution, every non-empty clause in Γ consists entirely\\nof negative literals.\\nNow let H be the set of all partial assignments for P with domain size at most k + 1\\nthat do not falsify any clause in Φ ∪ Γ under the direct encoding.\\nConsider any element f ∈ H. By the deﬁnition of H, f does not falsify any clause of\\nΦ, so by the deﬁnition of the direct encoding, every element of H is a partial solution to\\nP. Furthermore, if f extends g, then g is also an element of H, because g makes fewer\\nassignments than f and hence cannot falsify any additional clauses to f.\\nIf Φ has no negative-hyper-resolution refutation of width at most k, then Γ does not\\ncontain the empty clause, so H contains (at least) the partial solution with empty domain,\\nand hence H is not empty.\\nNow let f be any element of H with |Dom(f)| ≤ k and let v be any variable of P\\nthat is not in Dom(f). For any partial assignment g that extends f and has Dom(g) =\\nDom(f) ∪ {v} we have that either g ∈ H or else there exists a clause in Φ ∪ Γ that is\\nfalsiﬁed by g. Since g is a partial assignment, any clause C in Φ ∪ Γ that is falsiﬁed by g,\\nmust consist entirely of negative literals. Hence the literals of C must either be of the form\\n¬xwf(w) for some w ∈ Dom(f), or else ¬xvg(v). Moreover, any such clause must contain the\\nliteral ¬xvg(v), or else it would already be falsiﬁed by f.\\nAssume, for contradiction, that H does not contain any assignment g that extends f and\\nhas Dom(g) = Dom(f) ∪ {v}. In that case, we have that, for each i ∈ Dv, Φ ∪ Γ contains a\\nclause Ci consisting of negative literals of the form ¬xwf(w) for some w ∈ Dom(f), together\\nwith the literal ¬xvi. Now consider the clause, C, which is the negative-hyper-resolvent\\nof these clauses Ci and the at-least-one clause �\\ni∈Dv xvi. The clause C consists entirely\\nof negative literals of the form ¬xwf(w) for some w ∈ Dom(f), so it has width at most\\n|Dom(f)| ≤ k, and hence is an element of Γ. However C is falsiﬁed by f, which contradicts\\nthe choice of f. Hence we have shown that for all f ∈ H with |Dom(f)| ≤ k, and for\\n335\\nJeavons & Petke\\nall variables v such that v ̸∈ Dom(f), there is some g ∈ H such that g extends f and\\nv ∈ Dom(g).\\nWe have shown that H satisﬁes all the conditions required by Lemma 1, so we conclude\\nthat the k-consistency closure of P is non-empty.\\n2\\nLemma 3 Let P be a CSP instance, and let Φ be its direct encoding as a set of clauses.\\nIf the k-consistency closure of P is non-empty, then Φ has no negative-hyper-resolution\\nrefutation of width k or less.\\nProof.\\nLet V be the set of variables of P, where each v ∈ V has domain Dv, and let\\nX = {xvi | v ∈ V, i ∈ Dv} be the corresponding set of Boolean variables in Φ.\\nBy Lemma 1, if the k-consistency closure of P is non-empty, then there exists a non-\\nempty set H of partial solutions to P which satisﬁes the three properties described in\\nLemma 1.\\nNow consider any negative-hyper-resolution derivation Γ from Φ of width at most k. We\\nshow by induction on the length of this derivation that the elements of H do not falsify any\\nclause in the derivation. First we note that the elements of H are partial solutions, so they\\nsatisfy all the constraints of P, and hence do not falsify any clause of Φ. This establishes\\nthe base case. Assume, for induction, that all clauses in the derivation earlier than some\\nclause C are not falsiﬁed by any element of H.\\nNote that, apart from the at-least-one clauses, all clauses in Φ and Γ consist entirely of\\nnegative literals. Hence we may assume, without loss of generality, that C is the negative-\\nhyper-resolvent of a set of clauses ∆ = {Ci ∨ ¬xvi | i ∈ Dv} and the at-least-one clause\\n�\\ni∈Dv xvi, for some ﬁxed variable v.\\nIf f ∈ H falsiﬁes C, then the literals of C must all be of the form ¬xwf(w), for some\\nw ∈ Dom(f). Since the width of the derivation is at most k, C contains at most k literals,\\nand hence we may assume that |Dom(f)| ≤ k. But then, by the choice of H, there must\\nexist some extension g of f in H such that v ∈ Dom(g). Any such g will falsify some\\nclause in ∆, which contradicts our inductive hypothesis. Hence no f ∈ H falsiﬁes C, and,\\nin particular, C cannot be empty.\\nIt follows that no negative-hyper-resolution derivation of width at most k can contain\\nthe empty clause.\\n2\\nNote that the proof of Theorem 1 applies to any sparse encoding that contains the\\nat-least-one clauses for each variable, and where all other clauses are purely negative. We\\nwill call such an encoding a negative sparse encoding. As well as the direct encoding, other\\nnegative sparse encodings exist. For example, we may use negative clauses that involve only\\na subset of the variables in the scope of some constraints (to forbid tuples where all possible\\nextensions to the complete scope are disallowed by the constraint). Another example of\\na negative sparse encoding is a well-known variant of the direct encoding in which the\\nat-most-one clauses are omitted.\\nCorollary 1 The k-consistency closure of a CSP instance P is empty if and only if any\\nnegative sparse encoding of P has a negative-hyper-resolution refutation of width at most k.\\n336\\nLocal Consistency and SAT-Solvers\\n4. Negative-Hyper-Resolution and SAT-Solvers\\nIn this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and\\nDarwiche (2009) to show that for any ﬁxed k, the existence of a negative-hyper-resolution\\nrefutation of width k is likely to be discovered by a SAT-solver in polynomial-time using\\nstandard clause learning and restart techniques, even with a totally random branching\\nstrategy.\\nNote that previous results about the power of clause-learning SAT-solvers have generally\\nassumed an optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat\\n& Darwiche, 2009) - they have shown what solvers are potentially capable of doing, rather\\nthan what they are likely to achieve in practice.\\nAn important exception is the paper\\nby Atserias et al. (2011), which gives an analysis of likely behaviour, but relies on the\\nexistence of a standard resolution proof of bounded width. Here we show that the results\\nof Atserias et al. can be extended to hyper-resolution proofs, which can be shorter and\\nnarrower than their associated standard resolution proofs.\\nWe will make use of the following terminology from Atserias et al. (2011). For a clause\\nC, a Boolean variable x, and a truth value a ∈ {0, 1}, the restriction of C by the assignment\\nx = a, denoted C|x=a, is deﬁned to be the constant 1, if the assignment satisﬁes the clause,\\nor else the clause obtained by deleting from C any literals involving the variable x. For\\nany sequence of assignments S of the form (x1 = a1, x2 = a2, . . . , xr = ar) we write C|S to\\ndenote the result of computing the restriction of C by each assignment in turn. If C|S is\\nempty, then we say that the assignments in S falsify the clause C. For a set of clauses ∆,\\nwe write ∆|S to denote the set {C|S | C ∈ ∆} \\\\ {1}.\\nMost current SAT-solvers operate in the following way (Atserias et al., 2011; Pipat-\\nsrisawat & Darwiche, 2009). They maintain a database of clauses ∆ and a current state\\nS, which is a partial assignment of truth values to the Boolean variables in the clauses of\\n∆. A high-level description of the algorithms used to update the clause database and the\\nstate, derived from the description given in Atserias et al., is shown in Algorithm 1 (a sim-\\nilar framework, using slightly diﬀerent terminology, is given in Pipatsrisawat & Darwiche,\\n2009).\\nNow consider a run of the algorithm shown in Algorithm 1, started with the initial\\ndatabase ∆, and the empty state S0, until it either halts or discovers a conﬂict (i.e., ∅ ∈ ∆|S).\\nSuch a run is called a complete round started with ∆, and we represent it by the sequence\\nof states S0, . . . , Sm, that the algorithm maintains. Note that each state Si extends the\\nstate Si−1 by a single assignment to a Boolean variable, which may be either a decision\\nassignment or an implied assignment.\\nMore generally, a round is an initial segment S0, S1, . . . , Sr of a complete round started\\nwith ∆, up to a state Sr such that either ∆|Sr contains the empty clause, or ∆|Sr does not\\ncontain any unit clause. For any clause C, we say that a round S0, S1, . . . , Sr satisﬁes C if\\nC|Sr = 1, and we say that the round falsiﬁes C if C|Sr is empty.\\nIf S0, S1, . . . , Sr is a round started with ∆, and ∆|Sr contains the empty clause, then\\nthe algorithm either reports unsatisﬁability or learns a new clause: such a round is called\\nconclusive. If a round is not conclusive we call it inconclusive 2. Note that if S0, S1, . . . , Sr\\nis an inconclusive round started with ∆, then ∆|Sr does not contain the empty clause,\\n2. Note that a complete round that assigns all variables and reports satisﬁability is called inconclusive.\\n337\\nJeavons & Petke\\nand does not contain any unit clauses. Hence, for any clause C ∈ ∆, if Sr falsiﬁes all the\\nliterals of C except one, then it must satisfy the remaining literal, and hence satisfy C. This\\nproperty of clauses is captured by the following deﬁnition.\\nDeﬁnition 4 (Atserias et al., 2011) Let ∆ be a set of clauses, C a non-empty clause, and\\nl a literal of C. We say that ∆ absorbs C at l if every inconclusive round started with ∆\\nthat falsiﬁes C \\\\ {l} satisﬁes C.\\nIf ∆ absorbs C at each literal l in C, then we simply say that ∆ absorbs C.\\nNote that a closely related notion is introduced by Pipatsrisawat and Darwiche (2009) for\\nclauses that are not absorbed by a set of clauses ∆; they are referred to as 1-empowering with\\nrespect to ∆. (The exact relationship between 1-empowering and absorption is discussed\\nin Atserias et al., 2011.)\\nWe will now explore the relationship between absorption and negative-hyper-resolution.\\nExample 5 Let ∆ be the direct encoding of a CSP instance P = (V, D, C), where V =\\n{u, v, w}, Du = Dv = Dw = {1, 2} and C contains two binary constraints: one forbids the\\nassignment of the value 1 to u and v simultaneously, and the other forbids the simultaneous\\nassignment of the value 2 to u and 1 to w. Let C also contain a ternary constraint that\\nforbids the assignment of the value 2 to all three variables simultaneously.\\n∆ = { xu1 ∨ xu2, xv1 ∨ xv2, xw1 ∨ xw2,\\n¬xu1 ∨ ¬xu2, ¬xv1 ∨ ¬xv2, ¬xw1 ∨ ¬xw2,\\n¬xu1 ∨ ¬xv1, ¬xu2 ∨ ¬xw1, ¬xu2 ∨ ¬xv2 ∨ ¬xw2 }.\\nThe clause ¬xv1 ∨ ¬xw1 is not contained in ∆, but can be obtained by negative-hyper-\\nresolution from the clauses xu1 ∨ xu2, ¬xu1 ∨ ¬xv1, ¬xu2 ∨ ¬xw1.\\nThis clause is absorbed by ∆, since every inconclusive round that sets xv1 = true must\\nset xw1 = false by unit propagation, and every inconclusive round that sets xw1 = true\\nmust set xv1 = false also by unit propagation.\\nExample 5 indicates that clauses that can be obtained by negative hyper-resolution from a\\nset of clauses ∆ are sometimes absorbed by ∆. The next result clariﬁes when this situation\\nholds.\\nLemma 4 Any negative-hyper-resolvent of a set of disjoint clauses is absorbed by that set\\nof clauses.\\nProof.\\nLet C be the negative-hyper-resolvent of a set of clauses ∆ = {Ci ∨ ¬xi | i =\\n1, 2, . . . , r} and a clause C′ = C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr, where each Ci is a (possibly empty)\\ndisjunction of negative literals, for 0 ≤ i ≤ r. Then C = C0 ∨ C1 ∨ · · · ∨ Cr by Deﬁnition 3.\\nBy Deﬁnition 4, we must show that ∆ ∪ C′ absorbs C at each of its literals. Assume all\\nbut one of the literals of C are falsiﬁed. Since the set of clauses ∆ ∪ C′ are assumed to be\\ndisjoint, the remaining literal l must belong to exactly one of the clauses in this set. There\\nare two cases to consider.\\n1. If l belongs to the clause C′, then all clauses in ∆ have all but one literals falsiﬁed, so\\nthe remaining literal ¬xi in each of these clauses is set to true, by unit propagation.\\nHence all literals in C′ are falsiﬁed, except for l, so l is set to true, by unit propagation.\\n338\\nLocal Consistency and SAT-Solvers\\n2. If l belongs to one of the clauses Ci ∨ ¬xi, then all of the remaining clauses in ∆ have\\nall but one literals falsiﬁed, so the corresponding literals ¬xj are set to true, by unit\\npropagation. Hence all literals in C′ are falsiﬁed, except for xi, so xi is set to true, by\\nunit propagation. But now all literals in Ci ∨ ¬xi are falsiﬁed, except for l, so l is set\\nto true by unit propagation.\\n2\\nThe next example shows that the negative-hyper-resolvent of a set of clauses that is not\\ndisjoint will not necessarily be absorbed by those clauses.\\nExample 6 Recall the set of clauses ∆ given in Example 5, which is the direct encoding of\\na CSP instance with three variables {u, v, w}, each with domain {1, 2}.\\nThe clause ¬xu2 ∨ ¬xv2 is not contained in ∆, but can be obtained by negative-hyper-\\nresolution from the clauses xw1 ∨ xw2, ¬xu2 ∨ ¬xv2 ∨ ¬xw2, ¬xu2 ∨ ¬xw1.\\nThis clause is not absorbed by ∆, since an inconclusive round that sets xv2 = true will\\nnot necessarily ensure that xu2 = false by unit propagation.\\nThe basic approach we shall use to establish our main results below is to show that any\\nclauses that can be obtained by bounded width negative-hyper-resolution from a given set\\nof clauses, but are not immediately absorbed (such as the one in Example 6) are likely\\nto become absorbed quite quickly because of the additional clauses that are added by\\nthe process of clause learning. Hence a clause-learning SAT-solver is likely to fairly rapidly\\nabsorb all of the clauses that can be derived from its original database of clauses by negative-\\nhyper-resolution.\\nIn particular, if the empty clause can be derived by negative-hyper-\\nresolution, then the solver will fairly rapidly absorb some literal and its complement, and\\nhence report unsatisﬁability (see the proof of Theorem 2 for details).\\nThe following key properties of absorption are established by Atserias et al. (2011).\\nLemma 5 (Atserias et al., 2011) Let ∆ and ∆′ be sets of clauses, and let C and C′ be\\nnon-empty clauses.\\n1. If C belongs to ∆, then ∆ absorbs C;\\n2. If C ⊆ C′ and ∆ absorbs C, then ∆ absorbs C′;\\n3. If ∆ ⊆ ∆′ and ∆ absorbs C, then ∆′ absorbs C.\\nTo allow further analysis, we need to make some assumptions about the learning scheme,\\nthe restart policy and the branching strategy used by our SAT-solver.\\nThe learning scheme is a rule that creates and adds a new clause to the database\\nwhenever there is a conﬂict. Such a clause is called a conﬂict clause, and each of its literals\\nis falsiﬁed by some assignment in the current state. If a literal is falsiﬁed by the i-th decision\\nassignment, or some later implied assignment before the (i+1)-th decision assignment, it is\\nsaid to be falsiﬁed at level i. If a conﬂict clause contains exactly one literal that is falsiﬁed\\nat the maximum possible level, it is called an asserting clause (Pipatsrisawat & Darwiche,\\n2009; Zhang, Madigan, Moskewicz, & Malik, 2001).\\nAssumption 1 The learning scheme chooses an asserting clause.\\n339\\nJeavons & Petke\\nAlgorithm 1 Framework for a typical clause-learning SAT-solver\\nInput: ∆ : set of clauses;\\nS : partial assignment of truth values to variables.\\n1. while ∆|S ̸= ∅ do\\n2.\\nif ∅ ∈ ∆|S then\\nConflict\\n3.\\nif S contains no decision assignments then\\n4.\\nprint “UNSATISFIABLE” and halt\\n5.\\nelse\\n6.\\napply the learning scheme to add a new clause to ∆\\n7.\\nif restart policy says restart then\\n8.\\nset S = ∅\\n9.\\nelse\\n10.\\nselect most recent conﬂict-causing unreversed decision assignment in S\\n11.\\nreverse this decision, and remove all later assignments from S\\n12.\\nend if\\n13.\\nend if\\n14.\\nelse if {l} ∈ ∆|S for some literal l then\\nUnit Propagation\\n15.\\nadd to S the implied assignment x = a which satisﬁes l\\n16.\\nelse\\nDecision\\n17.\\napply the branching strategy to choose a decision assignment x = a\\n18.\\nadd this decision assignment to S\\n19.\\nend if\\n20. end while\\n21. print “SATISFIABLE” and output S\\nMost learning schemes in current use satisfy this assumption (Pipatsrisawat & Dar-\\nwiche, 2009; Zhang et al., 2001), including the learning schemes called “1UIP” and “De-\\ncision” (Zhang et al., 2001).\\nWe make no particular assumption about the restart policy. However, our main result\\nis phrased in terms of a bound on the expected number of restarts. If the algorithm restarts\\nafter r conﬂicts, our bound on the expected number of restarts can simply be multiplied\\nby r to get a bound on the expected number of conﬂicts.\\nThis means that the results\\nwill be strongest if the algorithm restarts immediately after each conﬂict. In that case,\\nr = 1 and our bound will also bound the expected number of conﬂicts. Existing SAT-\\nsolvers typically do not employ such an aggressive restart policy, but we note the remark\\nin the work of Pipatsrisawat and Darwiche (2009, p.666) that “there has been a clear trend\\ntowards more and more frequent restarts for modern SAT solvers”.\\nThe branching strategy determines which decision assignment is chosen after an incon-\\nclusive round that is not complete. In most current SAT solvers the strategy is based on\\nsome heuristic measure of variable activity, which is related to the occurrence of a variable in\\nconﬂict clauses (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). However, to simplify\\nthe probabilistic analysis, we will make the following assumption.\\n340\\nLocal Consistency and SAT-Solvers\\nAssumption 2 The branching strategy chooses a variable uniformly at random amongst\\nthe unassigned variables, and assigns it the value TRUE.\\nAs noted by Atserias et al. (2011), the same analysis we give below can also be applied\\nto any other branching strategy that randomly chooses between making a heuristic-based\\ndecision or a randomly-based decision. More precisely, if we allow, say, c > 1 rounds of non-\\nrandom decisions between random ones, then the number of required restarts and conﬂicts\\nwould appear multiplied by a factor of c.\\nAn algorithm that behaves according to the description in Algorithm 1, and satisﬁes\\nthe assumptions above, will be called a standard randomised SAT-solver.\\nTheorem 2 If a set of non-empty clauses ∆ over n Boolean variables has a negative-\\nhyper-resolution refutation of width k and length m, then the expected number of restarts\\nrequired by a standard randomised SAT-solver to discover that ∆ is unsatisﬁable is less than\\nmnk2�n\\nk\\n�.\\nProof. Let C1, C2, . . . , Cm be a negative-hyper-resolution refutation of width k from ∆,\\nwhere Cm is the ﬁrst occurrence of the empty clause. Since each clause in ∆ is non-empty,\\nCm must be derived by negative-hyper-resolution from some collection of negative literals\\n¬x1, ¬x2, . . . ¬xd and a purely positive clause x1 ∨ x2 ∨ · · · ∨ xd ∈ ∆.\\nNow consider a standard randomised SAT-solver started with database ∆. Once all of\\nthe unit clauses ¬xi are absorbed by the current database, then, by Deﬁnition 4, any further\\ninconclusive round of the algorithm must assign all variables xi false, and hence falsify the\\nclause x1 ∨x2 ∨· · · xd. Since this happens even when no decision assignments are made, the\\nSAT-solver will report unsatisﬁability.\\nIt only remains to bound the expected number of restarts required until each clause\\nCi is absorbed, for 1 ≤ i < m. Let each Ci be the negative-hyper-resolvent of clauses\\nCi1, Ci2, . . . , Cir, each of the form C′\\nij∨¬xj, together with a clause Ci0 = C0∨x1∨x2∨· · ·∨xr\\nfrom ∆, where C0 is a (possibly empty) disjunction of negative literals. Assume also that\\neach clause Cij is absorbed by ∆ for j = 0, 1, . . . , r.\\nIf ∆ absorbs Ci, then no further learning or restarts are needed, so assume now that ∆\\ndoes not absorb Ci. By Deﬁnition 4, this means that there exists some literal l and some\\ninconclusive round R started with ∆ that falsiﬁes Ci \\\\ {l} and does not satisfy Ci. Note\\nthat R must leave the literal l unassigned, because one assignment would satisfy Ci and\\nthe other would falsify C0 and each C′\\nij, and hence force all of the literals ¬xj used in the\\nnegative-hyper-resolution step to be satisﬁed, because each Cij is absorbed by ∆, so Ci0\\nwould be falsiﬁed, contradicting the fact that R is inconclusive.\\nHence, if the branching strategy chooses to falsify the literals Ci \\\\ {l} whenever it has\\na choice, it will construct an inconclusive round R′ where l is unassigned (since all the\\ndecision assignments in R′ are also assigned the same values in R, any implied assignments\\nin R′ must also be assigned the same values3 in R, but we have shown that R leaves l\\nunassigned). If the branching strategy then chooses to falsify the remaining literal l of Ci,\\nthen the algorithm would construct a conclusive round R′′ where Ci0 is falsiﬁed, and all\\n3. See Lemmas 5, 8 and 10 in the work of Atserias et al. (2011) for a more formal statement and proof of\\nthis assertion.\\n341\\nJeavons & Petke\\ndecision assignments falsify literals in Ci. Hence, by Assumption 1, the algorithm would\\nthen learn some asserting clause C′ and add it to ∆ to obtain a new set ∆′.\\nSince C′ is an asserting clause, it contains exactly one literal, l′, that is falsiﬁed at the\\nhighest level in R′′. Hence, any inconclusive round R started with ∆′ that falsiﬁes Ci \\\\ {l}\\nwill falsify all but one literal of C′, and hence force the remaining literal l′ to be satisﬁed,\\nby unit propagation. If this new implied assignment for l′ propagates to force l to be true,\\nthen R satisﬁes Ci, and hence ∆′ absorbs Ci at l. If not, then the branching strategy can\\nonce again choose to falsify the remaining literal l of Ci, which will cause a new asserting\\nclause to be learned and added to ∆. Since each new asserting clause forces a new literal to\\nbe satisﬁed after falsifying Ci \\\\ {l} this process can be repeated fewer than n times before\\nit is certain that ∆′ absorbs Ci at l.\\nNow consider any sequence of k random branching choices. If the ﬁrst k − 1 of these\\neach falsify a literal of Ci \\\\ {l}, and the ﬁnal choice falsiﬁes l, then we have shown that the\\nassociated round will reach a conﬂict, and add an asserting clause to ∆. With a random\\nbranching strategy, as described in Assumption 2, the probability that this happens is at\\nleast the probability that the ﬁrst k − 1 random choices consist of a ﬁxed set of variables\\n(in some order), and the ﬁnal choice is the variable associated with l.\\nThe number of\\nrandom choices that fall in a ﬁxed set follows the hypergeometric distribution, so the overall\\nprobability of this is\\n1\\n( n\\nk−1)\\n1\\n(n−k+1) = 1/(k\\n�n\\nk\\n�).\\nTo obtain an upper bound on the expected number of restarts, consider the worst case\\nwhere we require n asserting clauses to be added to absorb each clause Ci at each of its k\\nliterals l. Since we require only an upper bound, we will treat each round as an independent\\ntrial with success probability p = 1/(k\\n�n\\nk\\n�), and consider the worst case where we have to\\nachieve (m − 1)nk successes to ensure that Ci for 1 ≤ i < m is absorbed. In this case the\\ntotal number of restarts will follow a negative binomial distribution, with expected value\\n(m − 1)nk/p. Hence in all cases the expected number of restarts is less than mnk2�n\\nk\\n�.\\n2\\nA tighter bound on the number of restarts can be obtained if we focus on the Decision\\nlearning scheme (Atserias et al., 2011; Zhang et al., 2001), as the next result indicates.\\nTheorem 3 If a set of non-empty clauses ∆ over n Boolean variables has a negative-hyper-\\nresolution refutation of width k and length m, then the expected number of restarts required\\nby a standard randomised SAT-solver using the Decision learning scheme to discover that\\n∆ is unsatisﬁable is less than m\\n�n\\nk\\n�.\\nProof. The proof is similar to the proof of Theorem 2, except that the Decision learn-\\ning scheme has the additional feature that the literals in the chosen conﬂict clause falsify a\\nsubset of the current decision assignments. Hence in the situation we consider, where the\\ndecision assignments all falsify literals of some clause Ci, this learning scheme will learn a\\nsubset of Ci, and hence immediately absorb Ci, by Lemma 5 (1,2). Hence the maximum\\nnumber of learnt clauses required is reduced from (m−1)nk to (m−1), and the probability\\nis increased from 1/(k\\n�n\\nk\\n�) to 1/\\n�n\\nk\\n�, giving the tighter bound.\\n2\\nNote that a similar argument shows that the standard deviation of the number of restarts\\nis less than the standard deviation of a negative binomial distribution with parameters m\\n342\\nLocal Consistency and SAT-Solvers\\nand 1/\\n�n\\nk\\n�, which is less than √m\\n�n\\nk\\n�. Hence, by Chebyshev’s inequality (one-tailed version),\\nthe probability that a standard randomised SAT-solver using the decision learning scheme\\nwill discover that ∆ is unsatisﬁable after (m + √m)\\n�n\\nk\\n� restarts is greater than 1/2.\\n5. k-Consistency and SAT-Solvers\\nBy combining Theorem 1 and Theorem 3 we obtain the following result linking k-consistency\\nand SAT-solvers.\\nTheorem 4 If the k-consistency closure of a CSP instance P is empty, then the expected\\nnumber of restarts required by a standard randomised SAT-solver using the Decision learn-\\ning scheme to discover that the direct encoding of P is unsatisﬁable is O(n2kd2k), where n\\nis the number of variables in P and d is the maximum domain size.\\nProof. The length m of a negative-hyper-resolution refutation of width k is bounded\\nby the number of possible no-goods of length at most k for P, which is �k\\ni=1 di�n\\ni\\n�. Hence,\\nby Theorem 1 and Theorem 3 we obtain a bound of\\n��k\\ni=1 di�n\\ni\\n�� �nd\\nk\\n�, which is O(n2kd2k). 2\\nHence a standard randomised SAT-solver with a suitable learning strategy will decide\\nthe satisﬁability of any CSP instance with tree-width k with O(n2kd2k) expected restarts,\\neven when it is set to restart immediately after each conﬂict. In particular, the satisﬁability\\nof any tree-structured binary CSP instance (i.e., with tree-width 1) will be decided by such\\na solver with at most O(n2d2) expected conﬂicts, which is comparable with the growth rate\\nof an optimal arc-consistency algorithm for binary constraints. Note that this result cannot\\nbe obtained directly from the work of Atserias et al. (2011), because the direct encoding of\\nan instance with tree-width k is a set of clauses whose tree-width may be as high as dk.\\nMoreover, a standard randomised SAT-solver will decide the satisﬁability of any CSP\\ninstance, with any structure, within the same polynomial bounds, if the constraint relations\\nsatisfy certain algebraic properties that ensure bounded width (Barto & Kozik, 2009).\\nExamples of such constraint types include the “0/1/all” relations, deﬁned by Cooper et al.\\n(1994), and the “connected row-convex” relations, deﬁned by Deville et al. (1997), which\\ncan both be decided by 2-consistency.\\nIt was shown by Gent (2002) that the support encoding of a binary CSP instance can\\nbe made arc-consistent (that is, 1-consistent) by applying unit propagation alone. Hence, a\\nstandard SAT-solver will mimic the eﬀect of enforcing arc-consistency on such an encoding\\nbefore making any decisions or restarts. By combining Theorem 4 with the observation in\\nExample 4 that the direct encoding can be obtained from the support encoding by negative-\\nhyper-resolution, we obtain the following corollary concerning the support encoding for all\\nhigher levels of consistency.\\nCorollary 2 For any k ≥ 2, if the k-consistency closure of a binary CSP instance P\\nis empty, then the expected number of restarts required by a standard randomised SAT-\\nsolver using the Decision learning scheme to discover that the support encoding of P is\\nunsatisﬁable is O(n2kd2k), where n is the number of variables in P and d is the maximum\\ndomain size.\\n343\\nJeavons & Petke\\nThe CSP literature describes many variations on the notion of consistency.\\nIn this\\npaper we have considered k-consistency only. We note that our results can be generalised\\nto some other types of consistency such as singleton arc-consistency (Bessi`ere, 2006). The\\nextension to singleton arc-consistency follows from the recent discovery that if a family of\\nCSP instances is solvable by enforcing singleton arc-consistency, then the instances have\\nbounded width (Chen, Dalmau, & Grußien, 2011). In other words, all such instances can\\nbe solved by enforcing k-consistency, for some ﬁxed k. Hence, by Theorem 4, they will be\\nsolved in polynomial expected time by a standard randomised SAT-solver.\\n6. Experimental Results\\nThe polynomial upper bounds we obtain in this paper are not asymptotic, they apply for\\nall values of n, m and k. However, they are very conservative, and are likely to be met very\\neasily in practice.\\nTo investigate how an existing SAT-solver actually performs, we measured the runtime\\nof the MiniSAT solver (E´en & S¨orensson, 2003), version 2.2.0, on a family of CSP instances\\nthat can be decided by a ﬁxed level of consistency. For comparison, we also ran our ex-\\nperiments on two state-of-the-art constraint solvers: we used Minion (Gent, Jeﬀerson, &\\nMiguel, 2006), version 0.12, and the G12 ﬁnite domain solver (Nethercote et al., 2007),\\nversion 1.4.\\nTo match the simpliﬁed assumptions of our analysis more closely, we ran a further\\nset of experiments on a core version of MiniSAT in order to get a solver that uses only\\nunit propagation and conﬂict-directed learning with restarts. We also modiﬁed the solver to\\nfollow the random branching strategy described above. Our solver does not delete any learnt\\nclauses and uses an extreme restart policy that makes it restart whenever it encounters a\\nconﬂict. It uses the same learning scheme as MiniSAT. We refer to this modiﬁed solver as\\nsimple-MiniSAT.\\nAs the characteristic feature of the instances tested is their relatively low tree-width,\\nwe also used the Toulbar2 solver (Sanchez et al., 2008). This solver implements the BTD\\n(Backtracking with Tree-Decomposition) technique which has been shown to be eﬃcient\\nin practice, in contrast to earlier methods that had been proposed to attempt to exploit\\ntree-decompositions of the input problem (J´egou & Terrioux, 2003). As the problem of\\nﬁnding a tree-decomposition of minimal width (i.e., the tree-width) is NP-hard, the BTD\\ntechnique uses some approximations (described in J´egou & Terrioux, 2003). We note here\\nthat Toulbar2 is designed for solving optimization problems, namely weighted CSPs, or\\nWCSPs. In a WCSP instance, certain partial assignments have an associated cost. However,\\nthe Toulbar2 solver can be used to solve standard CSPs by simply setting all costs to 0.\\nFor all of the results, the times given are elapsed times on a Lenovo 3000 N200 laptop\\nwith an Intel Core 2 Duo processor running at 1.66GHz with 2GB of RAM. Each generated\\ninstance was run ﬁve times and the mean times and mean number of restarts are shown4.\\nExample 7 We consider a family of instances speciﬁed by two parameters, w and d. They\\nhave ((d−1)∗w+2)∗w variables arranged in groups of size w, each with domain {0, ..., d−1}.\\n4. MiniSAT and simple-MiniSAT were run with diﬀerent seeds for each of the ﬁve runs of an instance.\\nInstances marked with * were run once only.\\nThe runtime of simple-MiniSAT on those instances\\nexceeded 6 hours. Moreover, Toulbar2 was run with parameter B = 1 which enables BTD.\\n344\\nLocal Consistency and SAT-Solvers\\nWe impose a constraint of arity 2w on each pair of successive groups, requiring that the\\nsum of the values assigned to the ﬁrst of these two groups should be strictly smaller than\\nthe sum of the values assigned to the second. This ensures that the instances generated are\\nunsatisﬁable. An instance with w = 2 and d = 2 is shown diagrammatically and deﬁned\\nusing the speciﬁcation language MiniZinc (Nethercote et al., 2007) in Figure 1 (a) and (b)\\nrespectively5. A similar format is used for Toulbar2 6 and the same instance encoded in\\nthis format is shown in Figure 1 (c) (note that each hard constraint has cost 0).\\n(a) Graphical representation.\\narray[1..4] of var 0..1 : X1;\\narray[1..4] of var 0..1 : X2;\\nconstraint\\nforall(i in 1..3)(\\nX1[i] + X2[i] < X1[i + 1] + X2[i + 1]);\\nsolve satisfy;\\n(b) Speciﬁcation in MiniZinc.\\nchain\\nx1 0 1\\nx2 0 1\\nx3 0 1\\nx4 0 1\\nx5 0 1\\nx6 0 1\\nx7 0 1\\nx8 0 1\\nhard( x1 + x2 < x3 + x4 )\\nhard( x3 + x4 < x5 + x6 )\\nhard( x5 + x6 < x7 + x8 )\\n(c) Speciﬁcation in cp format.\\nFigure 1: An example of a CSP instance with w = 2, d = 2 and tree-width = 3.\\nThe structure of the instances described in Example 7 has a simple tree-decomposition as a\\npath of nodes, with each node corresponding to a constraint scope. Hence the tree-width of\\nthese instances is 2w − 1 and they can be shown to be unsatisﬁable by enforcing (2w − 1)-\\nconsistency (Atserias et al., 2007). However, these instances cannot be solved eﬃciently\\nusing standard propagation algorithms which only prune individual domain values.\\nThe structure of the direct encoding of these instances also has a tree-decomposition\\nwith each node corresponding to a constraint scope in the original CSP instance. However,\\nbecause the direct encoding introduces d Boolean variables to represent each variable in the\\n5. In order to run an instance on a CP solver one must usually use a translator to convert the original\\nmodel. The MiniZinc distribution provides an mzn2fzn translator while for Minion one can use Tailor\\n(available at http://www.cs.st-andrews.ac.uk/∼andrea/tailor/).\\n6. A\\ncp2wcsp\\ntranslator\\nand\\na\\ndescription\\nof\\nthe\\ncp\\nand\\nwcsp\\nformats\\nis\\navailable\\nat\\nhttp://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/SoftCSP.\\n345\\nJeavons & Petke\\noriginal instance, the tree-width of the encoded SAT instances is larger by approximately a\\nfactor of d; it is in fact 2wd − 1 (see Figure 2).\\n(a) Tree-decomposition of the origi-\\nnal instance.\\n(b) Tree-decomposition of its direct\\nencoding.\\nFigure 2: Tree-decompositions of the CSP instance from Figure 1.\\nTable 1 shows the runtimes of simple-MiniSAT and the original MiniSAT solver on\\nthis family of instances, along with times for the two state-of-the-art CP solvers and the\\nWCSP solver Toulbar2. By far the best solver for this set of instances is Toulbar2,\\nwhich is explicitly designed to exploit low tree-width by constructing a tree-decomposition.\\nFor the class of instances we are considering, the widths of the tree-decompositions found\\nby Toulbar2 matched the tree-widths of the instances tested (i.e., 2w − 1).\\nHowever, we also note that MiniSAT is remarkably eﬀective in solving these chains\\nof inequalities, compared to Minion and G12, even though the use of MiniSAT requires\\nencoding each instance into a large number of clauses with a much larger tree-width than\\nthe original. Although our simpliﬁed version of the MiniSAT solver takes a little longer\\nthan the current highly optimised version, it still performs very well on these instances in\\ncomparison with the conventional CP solvers. Moreover, the number of restarts (and hence\\nthe number of conﬂicts) appears to grow only polynomially with the size of the instance\\n(see Figure 3). In all cases the actual number of restarts is much lower than the polynomial\\nupper bound on the expected number of restarts given in Theorem 4.\\nOur best theoretical upper bounds on the expected run-time were obtained for the\\nDecision learning scheme (Theorem 4), but the standard version of MiniSAT uses the\\n1UIP learning scheme with conﬂict clause minimization.\\nTo allow a direct comparison\\nwith these theoretical upper bounds, we implemented the Decision scheme in simple-\\nMiniSAT. As the 1UIP learning scheme has generally been found to be more eﬃcient\\nin practice (Zhang et al., 2001), we switched oﬀ conﬂict clause minimization in simple-\\nMiniSAT in order to compare the two standard learning schemes and ran a further set of\\nexperiments. We counted the number of restarts for these two modiﬁed solvers on instances\\nof the form described in Example 7 - see Table 2.\\n346\\nLocal Consistency and SAT-Solvers\\ngroup\\ndomain\\nCSP\\nMinion\\nG12\\nToulbar2\\nMiniSAT\\nsimple-\\nsimple-\\nsize\\nsize\\nvariables\\nMiniSAT\\nMiniSAT\\n(w)\\n(d)\\n(n)\\n(sec)\\n(sec)\\n(sec)\\n(sec)\\n(sec)\\nrestarts\\n2\\n2\\n8\\n0.055\\n0.010\\n0.021\\n0.003\\n0.002\\n19\\n2\\n3\\n12\\n0.053\\n0.011\\n0.023\\n0.005\\n0.007\\n157\\n2\\n4\\n16\\n0.057\\n0.013\\n0.040\\n0.015\\n0.034\\n820\\n2\\n5\\n20\\n0.084\\n0.047\\n0.091\\n0.043\\n0.188\\n3 039\\n2\\n6\\n24\\n1.048\\n0.959\\n0.199\\n0.126\\n0.789\\n7 797\\n2\\n7\\n28\\n47.295\\n122.468\\n0.549\\n0.362\\n2.884\\n17 599\\n2\\n8\\n32\\n> 20 min\\n> 20 min\\n1.214\\n0.895\\n9.878\\n36 108\\n2\\n9\\n36\\n> 20 min\\n> 20 min\\n2.523\\n2.407\\n34.352\\n65 318\\n2\\n10\\n40\\n> 20 min\\n> 20 min\\n4.930\\n5.656\\n111.912\\n114 827\\n3\\n2\\n15\\n0.055\\n0.010\\n0.024\\n0.004\\n0.008\\n167\\n3\\n3\\n24\\n0.412\\n0.034\\n0.103\\n0.066\\n0.503\\n5 039\\n3\\n4\\n33\\n> 20 min\\n7.147\\n0.860\\n1.334\\n20.054\\n41 478\\n3\\n5\\n42\\n> 20 min\\n> 20 min\\n5.646\\n20.984\\n817.779\\n210 298\\n3\\n6\\n51\\n> 20 min\\n> 20 min\\n28.663\\n383.564\\n> 20 min\\n731 860\\n4\\n2\\n24\\n0.060\\n0.015\\n0.046\\n0.012\\n0.118\\n1 617\\n4\\n3\\n40\\n> 20 min\\n11.523\\n1.246\\n4.631\\n260.656\\n108 113\\n4\\n4\\n56\\n> 20 min\\n> 20 min\\n20.700\\n1,160.873\\n> 20 min\\n1 322 784*\\nTable 1: Average performance of solvers on instances from Example 7.\\ngroup\\ndomain\\nCSP\\nno. of clauses\\nsimple-\\nsimple-\\nsimple-\\nsimple-\\nsize\\nsize\\nvariables\\nin the direct\\nMiniSAT\\nMiniSAT\\nMiniSAT\\nMiniSAT\\n(w)\\n(d)\\n(n)\\nencoding\\n1UIP\\n1UIP\\nDecision\\nDecision\\n(sec)\\nrestarts\\n(sec)\\nrestarts\\n2\\n2\\n8\\n49\\n0.002\\n21\\n0.002\\n23\\n2\\n3\\n12\\n298\\n0.008\\n203\\n0.010\\n267\\n2\\n4\\n16\\n1 162\\n0.048\\n1 026\\n0.057\\n1 424\\n2\\n5\\n20\\n3 415\\n0.272\\n4 068\\n0.323\\n5 283\\n2\\n6\\n24\\n8 315\\n1.399\\n12 029\\n1.526\\n14 104\\n2\\n7\\n28\\n17 724\\n5.780\\n27 356\\n6.035\\n33 621\\n2\\n8\\n32\\n34 228\\n24.417\\n56 193\\n20.436\\n64 262\\n2\\n9\\n36\\n61 257\\n95.278\\n109 862\\n69.144\\n113 460\\n2\\n10\\n40\\n103 205\\n309.980\\n199 399\\n207.342\\n190 063\\n3\\n2\\n15\\n198\\n0.009\\n192\\n0.012\\n287\\n3\\n3\\n24\\n3 141\\n0.643\\n5 952\\n0.750\\n7 308\\n3\\n4\\n33\\n23 611\\n53.067\\n63 952\\n71.778\\n91 283\\n3\\n5\\n42\\n113 406\\n2,266.627\\n375 849\\n2,036.456\\n391,664\\n3\\n6\\n51\\n408 720\\n> 6 hours\\n1 584 012*\\n> 6 hours\\n1 365 481*\\n4\\n2\\n24\\n863\\n0.141\\n1 937\\n0.192\\n2 592\\n4\\n3\\n40\\n34 666\\n603.241\\n155 842\\n938.836\\n253 153\\nTable 2: Average performance of simple-MiniSAT with the 1UIP and the Decision learn-\\ning schemes on instances from Example 7.\\n347\\nJeavons & Petke\\nFigure 3: Log-log plot of the number of restarts/conﬂicts used by simple-MiniSAT on the\\ninstances from Example 7. The solid lines show a growth function of d2w−2�nd/w\\n3\\n�,\\nwhere n is the number of CSP variables. This empirically derived polynomial\\nfunction appears to ﬁt the experimental data well, and is much lower than the\\nupper bound on the expected number of restarts calculated in Theorem 4 which\\nis O(d4w−2n4w−2).\\n348\\nLocal Consistency and SAT-Solvers\\nAlthough the performance of simple-MiniSAT with the Decision learning scheme\\nand the 1UIP scheme are signiﬁcantly worse than the performance of the original simple-\\nMiniSAT solver, only about twice as many restarts were required for each instance. Hence,\\nour theoretical upper bounds are still easily met for both of these standard learning schemes.\\n7. Conclusions\\nWe have shown that the notion of k-consistency can be precisely captured by a single\\ninference rule on the direct encoding of a CSP instance, restricted to deriving only clauses\\nwith at most k literals. We used this to show that a clause-learning SAT-solver with a purely\\nrandom branching strategy will simulate the eﬀect of enforcing k-consistency in expected\\npolynomial time, for all ﬁxed k. This is suﬃcient to ensure that such solvers are able to\\nsolve certain problem families much more eﬃciently than conventional CP solvers relying\\non GAC-propagation.\\nIn principle clause-learning SAT-solvers can also do much more. It is known that, with\\nan appropriate branching strategy and restart policy, they are able to p-simulate general\\nresolution (Beame et al., 2004; Pipatsrisawat & Darwiche, 2009), and general resolution\\nproofs can be exponentially shorter than the negative-hyper-resolution proofs we have con-\\nsidered here (Hwang & Mitchell, 2005). In practice, it seems that current clause-learning\\nSAT-solvers with highly-tuned learning schemes, branching strategies and restart policies\\nare often able to exploit structure in the Boolean encoding of a CSP instance even more\\neﬀectively than local consistency techniques. Hence considerable work remains to be done\\nin understanding the relevant features of instances which they are able to exploit, in order\\nto predict their eﬀectiveness in solving diﬀerent kinds of CSP instances.\\nAcknowledgments\\nWe would like to thank Albert Atserias and Marc Thurley for comments on the conference\\nversion of this paper, as well as the anonymous referees.\\nThe provision of an EPSRC\\nDoctoral Training Award to Justyna Petke is also gratefully acknowledged.\\nA preliminary version of this paper appeared in Proceedings of the 16th International\\nConference on Principles and Practice of Constraint Programming - CP2010.\\nReferences\\nAtserias, A., Bulatov, A. A., & Dalmau, V. (2007). On the power of k-consistency. In\\nInternational Colloquium on Automata, Languages and Programming - ICALP’07,\\npp. 279–290.\\nAtserias, A., & Dalmau, V. (2008). A combinatorial characterization of resolution width.\\nJournal of Computer and System Sciences, 74(3), 323–334.\\nAtserias, A., Fichte, J. K., & Thurley, M. (2011). Clause-learning algorithms with many\\nrestarts and bounded-width resolution.\\nJournal of Artiﬁcial Intelligence Research\\n(JAIR), 40, 353–373.\\nBacchus, F. (2007). GAC via unit propagation. In Principles and Practice of Constraint\\nProgramming - CP’07, pp. 133–147.\\n349\\nJeavons & Petke\\nBarto, L., & Kozik, M. (2009). Constraint satisfaction problems of bounded width. In\\nSymposium on Foundations of Computer Science - FOCS’09, pp. 595–603.\\nBeame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding and harnessing\\nthe potential of clause learning. Journal of Artiﬁcial Intelligence Research (JAIR),\\n22, 319–351.\\nBessi`ere, C. (2006). Constraint propagation. In Rossi, F., van Beek, P., & Walsh, T. (Eds.),\\nHandbook of Constraint Programming, chap. 3. Elsevier.\\nB¨uning, H., & Lettmann, T. (1999). Propositional logic: deduction and algorithms. Cam-\\nbridge tracts in theoretical computer science. Cambridge University Press.\\nChen, H., Dalmau, V., & Grußien, B. (2011). Arc consistency and friends. Computing\\nResearch Repository - CoRR, abs/1104.4993.\\nCooper, M. C. (1989). An optimal k-consistency algorithm. Artiﬁcial Intelligence, 41(1),\\n89–95.\\nCooper, M. C., Cohen, D. A., & Jeavons, P. (1994). Characterising tractable constraints.\\nArtiﬁcial Intelligence, 65(2), 347–361.\\nde Kleer, J. (1989). A comparison of ATMS and CSP techniques. In International Joint\\nConference on Artiﬁcial Intelligence - IJCAI’89, pp. 290–296.\\nDeville, Y., Barette, O., & Hentenryck, P. V. (1997). Constraint satisfaction over connected\\nrow convex constraints. In International Joint Conference on Artiﬁcial Intelligence -\\nIJCAI’97 (1), pp. 405–411.\\nE´en, N., & S¨orensson, N. (2003). An extensible SAT-solver. In Theory and Applications of\\nSatisﬁability Testing - SAT’03, pp. 502–518.\\nFreuder, E. C. (1978). Synthesizing constraint expressions. Communications of the ACM,\\n21(11), 958–966.\\nGent, I. P. (2002). Arc consistency in SAT. In European Conference on Artiﬁcial Intelligence\\n- ECAI’02, pp. 121–125.\\nGent, I. P., Jeﬀerson, C., & Miguel, I. (2006). Minion: A fast scalable constraint solver. In\\nEuropean Conference on Artiﬁcial Intelligence - ECAI’06, pp. 98–102.\\nHooker, J. N. (2006). Integrated Methods for Optimization (International Series in Oper-\\nations Research & Management Science). Springer-Verlag New York, Inc., Secaucus,\\nNJ, USA.\\nHoos, H. H. (1999). SAT-encodings, search space structure, and local search performance.\\nIn International Joint Conference on Artiﬁcial Intelligence - IJCAI’99, pp. 296–303.\\nHwang, J., & Mitchell, D. G. (2005). 2-way vs. d-way branching for CSP. In Principles and\\nPractice of Constraint Programming - CP’05, pp. 343–357.\\nJ´egou, P., & Terrioux, C. (2003). Hybrid backtracking bounded by tree-decomposition of\\nconstraint networks. Artiﬁcial Intelligence, 146(1), 43–75.\\nKolaitis, P. G., & Vardi, M. Y. (2000). A game-theoretic approach to constraint satisfac-\\ntion. In Conference on Artiﬁcial Intelligence - AAAI’00 / Innovative Applications of\\nArtiﬁcial Intelligence Conference - IAAI’00, pp. 175–181.\\n350\\nLocal Consistency and SAT-Solvers\\nMackworth, A. K. (1977). Consistency in networks of relations. Artiﬁcial Intelligence, 8(1),\\n99–118.\\nMontanari, U. (1974). Networks of constraints: Fundamental properties and applications to\\npicture processing. Information Sciences, 7, 95–132.\\nMoskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaﬀ: En-\\ngineering an eﬃcient SAT solver. In Design Automation Conference - DAC’01, pp.\\n530–535.\\nNethercote, N., Stuckey, P. J., Becket, R., Brand, S., Duck, G. J., & Tack, G. (2007).\\nMiniZinc: Towards a standard CP modelling language. In Principles and Practice of\\nConstraint Programming - CP’07, pp. 529–543.\\nPetke, J., & Jeavons, P. (2009). Tractable benchmarks for constraint programming. Tech-\\nnical Report RR-09-07, Department of Computer Science, University of Oxford.\\nPipatsrisawat, K., & Darwiche, A. (2009). On the power of clause-learning SAT solvers with\\nrestarts. In Principles and Practice of Constraint Programming - CP’09, pp. 654–668.\\nPrestwich, S. D. (2009). CNF encodings. In Biere, A., Heule, M., van Maaren, H., & Walsh,\\nT. (Eds.), Handbook of Satisﬁability, pp. 75–97. IOS Press.\\nRish, I., & Dechter, R. (2000). Resolution versus search: Two strategies for SAT. Journal\\nof Automated Reasoning, 24(1/2), 225–275.\\nRobinson, J. A. (1965). A machine-oriented logic based on the resolution principle. Journal\\nof the ACM, 12(1), 23–41.\\nSanchez, M., Bouveret, S., de Givry, S., Heras, F., J´egou, P., Larrosa, J., Ndiaye, S., Rollon,\\nE., Schiex, T., Terrioux, C., Verfaillie, G., & Zytnicki, M. (2008). Max-CSP compe-\\ntition 2008: Toulbar2 solver description. In Proceedings of the Third International\\nCSP Solver Competition.\\nSchiex, T., & Verfaillie, G. (1993). Nogood recording for static and dynamic constraint\\nsatisfaction problems. In International Conference on Tools with Artiﬁcial Intelligence\\n- ICTAI’93, pp. 48–55.\\nTamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling ﬁnite linear CSP\\ninto SAT. Constraints, 14(2), 254–272.\\nvan Dongen, M., Lecoutre, C., & Roussel, O. (2008). 3rd international CSP solver competi-\\ntion. Instances and results available at http://www.cril.univ-artois.fr/CPAI08/.\\nvan Dongen, M., Lecoutre, C., & Roussel, O. (2009). 4th international CSP solver competi-\\ntion. Instances and results available at http://www.cril.univ-artois.fr/CPAI09/.\\nWalsh, T. (2000). SAT v CSP. In Principles and Practice of Constraint Programming -\\nCP’00, pp. 441–456.\\nZhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Eﬃcient conﬂict driven\\nlearning in Boolean satisﬁability solver. In International Conference on Computer-\\nAided Design - ICCAD’01, pp. 279–285.\\nZhang, L., & Malik, S. (2002). The quest for eﬃcient Boolean satisﬁability solvers. In\\nComputer Aided Veriﬁcation - CAV’02, pp. 17–36.\\n351\\n', metadata={'Published': '2014-01-21', 'Title': 'Local Consistency and SAT-Solvers', 'Authors': ['Peter Jeavons', ' Justyna Petke'], 'Summary': '  Local consistency techniques such as k-consistency are a key component of\\nspecialised solvers for constraint satisfaction problems. In this paper we show\\nthat the power of using k-consistency techniques on a constraint satisfaction\\nproblem is precisely captured by using a particular inference rule, which we\\ncall negative-hyper-resolution, on the standard direct encoding of the problem\\ninto Boolean clauses. We also show that current clause-learning SAT-solvers\\nwill discover in expected polynomial time any inconsistency that can be deduced\\nfrom a given set of clauses using negative-hyper-resolvents of a fixed size. We\\ncombine these two results to show that, without being explicitly designed to do\\nso, current clause-learning SAT-solvers efficiently simulate k-consistency\\ntechniques, for all fixed values of k. We then give some experimental results\\nto show that this feature allows clause-learning SAT-solvers to efficiently\\nsolve certain families of constraint problems which are challenging for\\nconventional constraint-programming solvers.\\n', 'paper_id': '1401.4613', 'journal_ref': 'Journal Of Artificial Intelligence Research, Volume 43, pages\\n  329-351, 2012', 'categories': ['cs.AI', 'cs.LO'], 'source': 'http://arxiv.org/abs/1401.4613'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(model_name=\"text-embedding-ada-002\",allowed_special={\"<|endoftext|>\"},chunk_size=250, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(shared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23974"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts) // 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=len(texts) // 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_texts=len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in range(r+1):\n",
    "    start=i*4000\n",
    "    end=start+4000\n",
    "    if end>len_texts:\n",
    "        end=len_texts\n",
    "    a.append(texts[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1066"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995312\n",
      "995811\n",
      "995924\n",
      "996052\n",
      "996226\n",
      "989130\n"
     ]
    }
   ],
   "source": [
    "for aa in a:\n",
    "    cnt=0\n",
    "    for aaa in aa:\n",
    "        cnt+=len(encoding.encode(aaa.page_content))\n",
    "    print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "len(encoding.encode(texts[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter2 = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts2 = text_splitter2.split_documents(shared_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts2[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Journal of Artiﬁcial Intelligence Research 43 (2012) 329-351\\nSubmitted 11/11; published 03/12\\nLocal Consistency and SAT-Solvers\\nPeter Jeavons\\nPeter.Jeavons@cs.ox.ac.uk\\nJustyna Petke\\nJustyna.Petke@cs.ox.ac.uk\\nDepartment of Computer Science, University of Oxford\\nWolfson Building, Parks Road, Oxford, OX1 3QD, UK\\nAbstract\\nLocal consistency techniques such as k-consistency are a key component of specialised\\nsolvers for constraint satisfaction problems.\\nIn this paper we show that the power of\\nusing k-consistency techniques on a constraint satisfaction problem is precisely captured by\\nusing a particular inference rule, which we call negative-hyper-resolution, on the standard\\ndirect encoding of the problem into Boolean clauses. We also show that current clause-\\nlearning SAT-solvers will discover in expected polynomial time any inconsistency that can\\nbe deduced from a given set of clauses using negative-hyper-resolvents of a ﬁxed size. We', metadata={'Published': '2014-01-21', 'Title': 'Local Consistency and SAT-Solvers', 'Authors': ['Peter Jeavons', ' Justyna Petke'], 'Summary': '  Local consistency techniques such as k-consistency are a key component of\\nspecialised solvers for constraint satisfaction problems. In this paper we show\\nthat the power of using k-consistency techniques on a constraint satisfaction\\nproblem is precisely captured by using a particular inference rule, which we\\ncall negative-hyper-resolution, on the standard direct encoding of the problem\\ninto Boolean clauses. We also show that current clause-learning SAT-solvers\\nwill discover in expected polynomial time any inconsistency that can be deduced\\nfrom a given set of clauses using negative-hyper-resolvents of a fixed size. We\\ncombine these two results to show that, without being explicitly designed to do\\nso, current clause-learning SAT-solvers efficiently simulate k-consistency\\ntechniques, for all fixed values of k. We then give some experimental results\\nto show that this feature allows clause-learning SAT-solvers to efficiently\\nsolve certain families of constraint problems which are challenging for\\nconventional constraint-programming solvers.\\n', 'paper_id': '1401.4613', 'journal_ref': 'Journal Of Artificial Intelligence Research, Volume 43, pages\\n  329-351, 2012', 'categories': 493844    cs.AI cs.LO\n",
       "Name: categories, dtype: object, 'source': 'http://arxiv.org/abs/1401.4613'})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Journal of Artiﬁcial Intelligence Research 43 (2012) 329-351\\nSubmitted 11/11; published 03/12\\nLocal Consistency and SAT-Solvers\\nPeter Jeavons\\nPeter.Jeavons@cs.ox.ac.uk\\nJustyna Petke\\nJustyna.Petke@cs.ox.ac.uk\\nDepartment of Computer Science, University of Oxford\\nWolfson Building, Parks Road, Oxford, OX1 3QD, UK\\nAbstract\\nLocal consistency techniques such as k-consistency are a key component of specialised\\nsolvers for constraint satisfaction problems.\\nIn this paper we show that the power of\\nusing k-consistency techniques on a constraint satisfaction problem is precisely captured by\\nusing a particular inference rule, which we call negative-hyper-resolution, on the standard\\ndirect encoding of the problem into Boolean clauses. We also show that current clause-\\nlearning SAT-solvers will discover in expected polynomial time any inconsistency that can\\nbe deduced from a given set of clauses using negative-hyper-resolvents of a ﬁxed size. We\\ncombine these two results to show that, without being explicitly designed to do so, current\\nclause-learning SAT-solvers eﬃciently simulate k-consistency techniques, for all ﬁxed values\\nof k. We then give some experimental results to show that this feature allows clause-learning\\nSAT-solvers to eﬃciently solve certain families of constraint problems which are challenging\\nfor conventional constraint-programming solvers.\\n1. Introduction\\nOne of the oldest and most central ideas in constraint programming, going right back to\\nMontanari’s original paper in 1974, is the idea of using local consistency techniques to prune\\nthe search space (Bessi`ere, 2006). The idea of arc-consistency was introduced by Mackworth\\n(1977), and generalised to k-consistency by Freuder (1978).\\nModern constraint solvers\\ngenerally employ specialised propagators to prune the domains of variables to achieve some\\nform of generalised arc-consistency, but typically do not attempt to enforce higher levels of\\nconsistency, such as path-consistency.\\nBy contrast, the software tools developed to solve propositional satisﬁability problems,\\nknown as SAT-solvers, generally use logical inference techniques, such as unit propagation\\nand clause-learning, to prune the search space.\\nOne of the most surprising empirical ﬁndings of the last few years has been the remark-\\nably good performance of general SAT-solvers in solving constraint satisfaction problems.\\nTo apply such tools to a constraint satisfaction problem one ﬁrst has to translate the in-\\nstance into a set of clauses using some form of Boolean encoding (Tamura, Taga, Kitagawa,\\n& Banbara, 2009; Walsh, 2000).\\nSuch encoding techniques tend to obscure the struc-\\nture of the original problem, and may introduce a very large number of Boolean variables\\nand clauses to encode quite easily-stated constraints. Nevertheless, in quite a few cases,\\nsuch approaches have out-performed more traditional constraint-solving tools (van Dongen,\\nLecoutre, & Roussel, 2008, 2009; Petke & Jeavons, 2009).\\nc⃝2012 AI Access Foundation. All rights reserved.\\nJeavons & Petke\\nIn this paper we draw on a number of recent analytical approaches to try to account\\nfor the good performance of general SAT-solvers on many forms of constraint problems.\\nBuilding on the results of Atserias, Bulatov, and Dalmau (2007), Atserias and Dalmau\\n(2008), and Hwang and Mitchell (2005), we show that the power of using k-consistency\\ntechniques in a constraint problem is precisely captured by using a single inference rule in\\na standard Boolean encoding of that problem. We refer to this inference rule as negative-\\nhyper-resolution, and show that any conclusions deduced by enforcing k-consistency can be\\ndeduced by a sequence of negative-hyper-resolution inferences involving Boolean clauses in\\nthe original instance and negative-hyper-resolvents with at most k literals. Furthermore,\\nby using the approach of Atserias, Fichte, and Thurley (2011), and Pipatsrisawat and\\nDarwiche (2009), we show that current clause-learning SAT-solvers will mimic the eﬀect of\\nsuch deductions in polynomial expected time, even with a random branching strategy. Hence\\nwe show that, although they are not explicitly designed to do so, running a clause-learning\\nSAT-solver on a straightforward encoding of a constraint problem eﬃciently simulates the\\neﬀects of enforcing k-consistency for all values of k.\\n2. Preliminaries\\nIn this section we give some background and deﬁnitions that will be used throughout the\\nrest of the paper.\\n2.1 Constraint Satisfaction Problems and k-Consistency\\nDeﬁnition 1 An instance of the Constraint Satisfaction Problem (CSP) is speciﬁed\\nby a triple (V, D, C), where\\n• V is a ﬁnite set of variables;\\n• D = {Dv | v ∈ V } where each set Dv is the set of possible values for the variable v,\\ncalled the domain of v;\\n• C is a ﬁnite set of constraints. Each constraint in C is a pair (Ri, Si) where\\n– Si is an ordered list of mi variables, called the constraint scope;\\n– Ri is a relation over D of arity mi, called the constraint relation.\\nGiven any CSP instance (V, D, C), a partial assignment is a mapping f from some\\nsubset W of V to � Dv such that f(v) ∈ Dv for all v ∈ W. A partial assignment satisﬁes\\nthe constraints of the instance if, for all (R, (v1, v2, . . . , vm)) ∈ C such that vj ∈ W for\\nj = 1, 2, . . . , m, we have (f(v1), f(v2) . . . , f(vm)) ∈ R. A partial assignment that satisﬁes\\nthe constraints of an instance is called a partial solution1 to that instance.\\nThe set of\\nvariables on which a partial assignment f is deﬁned is called the domain of f, and denoted\\nDom(f).\\nA partial solution g extends a partial solution f if Dom(g) ⊇ Dom(f) and\\ng(v) = f(v) for all v ∈ Dom(f). A partial solution with domain V is called a solution.\\nOne way to derive new information about a CSP instance, which may help to determine\\nwhether or not it has a solution, is to use some form of constraint propagation to enforce\\n1. Note that not all partial solutions extend to solutions.\\n330\\nLocal Consistency and SAT-Solvers\\nsome level of local consistency (Bessi`ere, 2006). For example, it is possible to use the notion\\nof k-consistency, deﬁned below. We note that there are several diﬀerent but equivalent ways\\nto deﬁne and enforce k-consistency described in the literature (Bessi`ere, 2006; Cooper, 1989;\\nFreuder, 1978). Our presentation follows that of Atserias et al. (2007), which is inspired by\\nthe notion of existential k-pebble games introduced by Kolaitis and Vardi (2000).\\nDeﬁnition 2 (Atserias et al., 2007) For any CSP instance P, the k-consistency closure\\nof P is the set H of partial assignments which is obtained by the following algorithm:\\n1. Let H be the collection of all partial solutions f of P with |Dom(f)| ≤ k + 1;\\n2. For every f ∈ H with |Dom(f)| ≤ k and every variable v of P, if there is no g ∈ H\\nsuch that g extends f and v ∈ Dom(g), then remove f and all its extensions from H;\\n3. Repeat step 2 until H is unchanged.\\nNote that computing the k-consistency closure according to this deﬁnition corresponds\\nprecisely to enforcing strong (k+1)-consistency according to the deﬁnitions given by Bessi`ere\\n(2006), Cooper (1989), and Freuder (1978).\\nThroughout this paper, we shall assume that the domain of possible values for each\\nvariable in a CSP instance is ﬁnite. It is straightforward to show that for any ﬁxed k,\\nand any ﬁxed maximum domain size, the k-consistency closure of an instance P can be\\ncomputed in polynomial time (Atserias et al., 2007; Cooper, 1989).\\nNote that any solution to P must extend some element of the k-consistency closure of\\nP. Hence, if the k-consistency closure of P is empty, for some k, then P has no solutions.\\nThe converse is not true in general, but it holds for certain special cases, such as the class of\\ninstances whose structure has tree-width bounded by k (Atserias et al., 2007), or the class\\nof instances whose constraint relations are “0/1/all” relations, as deﬁned in Cooper, Cohen,\\nand Jeavons (1994), or “connected row-convex” relations, as deﬁned in Deville, Barette,\\nand Hentenryck (1997). For these special kinds of instances it is possible to determine in\\npolynomial time whether or not a solution exists simply by computing the k-consistency\\nclosure, for an appropriate choice of k.\\nMoreover, if a solution exists, then it can be\\nconstructed in polynomial time by selecting each variable in turn, assigning each possible\\nvalue, re-computing the k-consistency closure, and retaining an assignment that gives a\\nnon-empty result.\\nThe following result gives a useful condition for determining whether the k-consistency\\nclosure of a CSP instance is empty.\\nLemma 1 (Kolaitis & Vardi, 2000) The k-consistency closure of a CSP instance P is\\nnon-empty if and only if there exists a non-empty family H of partial solutions to P such\\nthat:\\n1. If f ∈ H, then |Dom(f)| ≤ k + 1;\\n2. If f ∈ H and f extends g, then g ∈ H;\\n3. If f ∈ H, |Dom(f)| ≤ k, and v /∈ Dom(f) is a variable of P, then there is some\\ng ∈ H such that g extends f and v ∈ Dom(g).\\nA set of partial solutions H satisfying the conditions described in Lemma 1 is sometimes\\ncalled a strategy for the instance P (Barto & Kozik, 2009; Kolaitis & Vardi, 2000).\\n331\\nJeavons & Petke\\n2.2 Encoding a CSP Instance as a Propositional Formula\\nOne possible approach to solving a CSP instance is to encode it as a propositional formula\\nover a suitable set of Boolean variables, and then use a program to decide the satisﬁability\\nof that formula. Many such programs, known as SAT-solvers, are now available and can\\noften eﬃciently handle problems with thousands, or sometimes even millions, of Boolean\\nvariables (Zhang & Malik, 2002).\\nSeveral diﬀerent ways of encoding a CSP instance as a propositional formula have been\\nproposed (Prestwich, 2009; Tamura et al., 2009; Walsh, 2000).\\nHere we consider one common family of encodings, known as sparse encodings (this term\\nwas introduced in Hoos, 1999). For any CSP instance P = (V, D, C), a sparse encoding\\nintroduces a set of Boolean variables of the form xvi for each v ∈ V and each i ∈ Dv. The\\nBoolean variable xvi is assigned True if and only if the original variable v is assigned the\\nvalue i. We will say that a partial assignment f falsiﬁes a clause C if C consists entirely of\\nliterals of the form ¬xvf(v), for variables v ∈ Dom(f). Otherwise, we will say that a partial\\nassignment f satisﬁes a clause C.\\nExample 1 Let P be a CSP instance such that V = {u, v, w}, Du = Dv = {0, 1}, Dw =\\n{0, 1, 2} and C contains a single ternary constraint with scope (u, v, w) specifying that\\nu ≤ v < w. A sparse encoding of P will introduce seven Boolean variables:\\nxu0, xu1, xv0, xv1, xw0, xw1, xw2.\\nSparse encodings usually contain certain clauses known as at-least-one and at-most-one\\nclauses, to ensure that each variable v is assigned a value, say i, and that no other value,\\nj ̸= i, is assigned to v. The at-least-one clauses are of the form �\\ni∈Dv xvi for each variable\\nv. The at-most-one clauses can be represented as a set of binary clauses ¬xvi ∨ ¬xvj for all\\ni, j ∈ Dv with i ̸= j.\\nExample 2 In the case of the CSP instance from Example 1 the at-least-one clauses are:\\nxu0 ∨ xu1, xv0 ∨ xv1, xw0 ∨ xw1 ∨ xw2\\nThe at-most-one clauses are:\\n¬xu0 ∨ ¬xu1, ¬xv0 ∨ ¬xv1, ¬xw0 ∨ ¬xw1, ¬xw0 ∨ ¬xw2, ¬xw1 ∨ ¬xw2\\nThe various diﬀerent sparse encodings diﬀer in the way they encode the constraints of a\\nCSP instance. Two methods are most commonly used. The ﬁrst one encodes the disallowed\\nvariable assignments - the so-called conﬂicts or no-goods. The direct encoding (Prestwich,\\n2009), for instance, generates a clause �\\nv∈S ¬xvf(v) for each partial assignment f that does\\nnot satisfy the constraint (R, S) ∈ C. Using the direct encoding, the ternary constraint\\nfrom Example 1 would be encoded by the following clauses:\\n¬xu0 ∨ ¬xv0 ∨ ¬xw0,\\n¬xu0 ∨ ¬xv1 ∨ ¬xw0,\\n¬xu0 ∨ ¬xv1 ∨ ¬xw1,\\n¬xu1 ∨ ¬xv0 ∨ ¬xw0,\\n332\\nLocal Consistency and SAT-Solvers\\n¬xu1 ∨ ¬xv0 ∨ ¬xw1,\\n¬xu1 ∨ ¬xv0 ∨ ¬xw2,\\n¬xu1 ∨ ¬xv1 ∨ ¬xw0,\\n¬xu1 ∨ ¬xv1 ∨ ¬xw1.\\nAnother way of translating constraints into clauses is to encode the allowed variable\\nassignments - the so-called supports. This has been used as the basis for an encoding of\\nbinary CSP instances, known as the support encoding (Gent, 2002), deﬁned as follows.\\nFor each pair of variables v, w in the scope of some constraint, and each value i ∈ Dv,\\nthe support encoding will contain the clause ¬xvi ∨ �\\nj∈A xwj, where A ⊆ Dw is the set of\\nvalues for the variable w which are compatible with the assignment v = i, according to the\\nconstraint.\\nNote that the support encoding is deﬁned for binary CSP instances only. However, some\\nnon-binary constraints can be decomposed into binary ones without introducing any new\\nvariables. For instance, the ternary constraint from Example 1 can be decomposed into two\\nbinary constraints specifying that u ≤ v and v < w. Using the support encoding, these\\nbinary constraints would then be represented by the following clauses:\\n¬xu0 ∨ xv0 ∨ xv1, ¬xu1 ∨ xv1, ¬xv0 ∨ xu0, ¬xv1 ∨ xu0 ∨ xu1,\\n¬xv0 ∨ xw1 ∨ xw2, ¬xv1 ∨ xw2, ¬xw0, ¬xw1 ∨ xv0, ¬xw2 ∨ xv0 ∨ xv1.\\n2.3 Inference Rules\\nGiven any set of clauses we can often deduce further clauses by applying certain inference\\nrules. For example, if we have two clauses of the form C1∨x and C2∨¬x, for some (possibly\\nempty) clauses C1, C2, and some variable x, then we can deduce the clause C1 ∨ C2. This\\nform of inference is known as propositional resolution; the resultant clause is called the\\nresolvent (Robinson, 1965).\\nIn the next section, we shall establish a close connection between the k-consistency\\nalgorithm and a form of inference called negative-hyper-resolution (B¨uning & Lettmann,\\n1999), which we deﬁne as follows:\\nDeﬁnition 3 If we have a collection of clauses of the form Ci ∨ ¬xi, for i = 1, 2, . . . , r,\\nand a clause C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr, where each xi is a Boolean variable, and C0 and\\neach Ci is a (possibly empty) disjunction of negative literals, then we can deduce the clause\\nC0 ∨ C1 ∨ · · · ∨ Cr.\\nWe call this form of inference negative-hyper-resolution and the resultant clause\\nC0 ∨ C1 ∨ · · · ∨ Cr the negative-hyper-resolvent.\\nIn the case where C0 is empty, the negative-hyper-resolution rule is equivalent to the\\nnogood resolution rule described by Hwang and Mitchell (2005) as well as the H5-k rule\\nintroduced by de Kleer (1989) and the nogood recording scheme described by Schiex and\\nVerfaillie (1993).\\nNote that the inference obtained by negative-hyper-resolution can also be obtained by a\\nsequence of standard resolution steps. However, the reason for introducing negative-hyper-\\nresolution is that it allows us to deduce the clauses we need in a single step without needing\\nto introduce intermediate clauses (which may contain up to r − 1 more literals than the\\n333\\nJeavons & Petke\\nnegative-hyper-resolvent). By restricting the size of the clauses we use in this way we are\\nable to obtain better performance bounds for SAT-solvers in the results below.\\nExample 3 Assume we have a collection of clauses of the form Ci∨¬xi, for i = 1, 2, . . . , r,\\nand a clause C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr, as speciﬁed in Deﬁnition 3, where each Ci = C0. The\\nnegative-hyper-resolvent of this set of clauses is C0.\\nThe clause C0 can also be obtained by a sequence of standard resolution steps, as follows.\\nFirst resolve C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr with C0 ∨ ¬xr to obtain C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr−1. Then\\nresolve this with the next clause, C0 ∨ ¬xr−1, and so on for the other clauses, until ﬁnally\\nwe obtain C0. However, in this case the intermediate clause C0∨x1∨x2∨· · ·∨xr−1 contains\\nr − 1 more literals than the negative-hyper-resolvent.\\nExample 4 Note that the no-good clauses in the direct encoding of a binary CSP instance\\ncan each be obtained by a single negative-hyper-resolution step from an appropriate support\\nclause in the support encoding together with an appropriate collection of at-most-one clauses.\\nLet A ⊆ Dw be the set of values for the variable w which are compatible with the assignment\\nv = i, then the support encoding will contain the clause C = ¬xvi ∨ �\\nj∈A xwj. If there are\\nany values k ∈ Dw which are incompatible with the assignment v = i, then we can form the\\nnegative-hyper-resolvent of C with the at-most-one clauses ¬xwk ∨ ¬xwj for each j ∈ A, to\\nobtain the corresponding no-good clause, ¬xvi ∨ ¬xwk.\\nA negative-hyper-resolution derivation of a clause C from a set of initial clauses Φ is\\na sequence of clauses C1, C2, . . . , Cm, where Cm = C and each Ci follows by the negative-\\nhyper-resolution rule from some collection of clauses, each of which is either contained in\\nΦ or else occurs earlier in the sequence. The width of this derivation is deﬁned to be the\\nmaximum size of any of the clauses Ci. If Cm is the empty clause, then we say that the\\nderivation is a negative-hyper-resolution refutation of Φ.\\n3. k-Consistency and Negative-Hyper-Resolution\\nIt has been pointed out by many authors that enforcing local consistency is a form of\\ninference on relations analogous to the use of the resolution rule on clauses (Bacchus, 2007;\\nBessi`ere, 2006; Hwang & Mitchell, 2005; Rish & Dechter, 2000). The precise strength of the\\nstandard resolution inference rule on the direct encoding of a CSP instance was considered\\nin the work of Walsh (2000), where it was shown that unit resolution (where one of the\\nclauses being resolved consists of a single literal), corresponds to enforcing a weak form of\\nlocal consistency known as forward checking. Hwang and Mitchell (2005) pointed out that\\nthe standard resolution rule with no restriction on clause length is able to simulate all the\\ninferences made by a k-consistency algorithm. Atserias and Dalmau (2008) showed that\\nthe standard resolution rule restricted to clauses with at most k literals, known as the k-\\nresolution rule, can be characterised in terms of the Boolean existential (k+1)-pebble game.\\nIt follows that on CSP instances with Boolean domains this form of inference corresponds\\nto enforcing k-consistency. An alternative proof that k-resolution achieves k-consistency for\\ninstances with Boolean domains is given in the book by Hooker (2006, Thm. 3.22).\\nHere we extend these results a little, to show that for CSP instances with arbitrary\\nﬁnite domains, applying the negative-hyper-resolution rule on the direct encoding to obtain\\n334\\nLocal Consistency and SAT-Solvers\\nclauses with at most k literals corresponds precisely to enforcing k-consistency. A similar\\nrelationship was stated in the work of de Kleer (1989), but a complete proof was not given.\\nNote that the bound, k, that we impose on the size of the negative-hyper-resolvents,\\nis independent of the domain size. In other words, using this inference rule we only need\\nto consider inferred clauses of size at most k, even though we make use of clauses in the\\nencoding whose size is equal to the domain size, which may be arbitrarily large.\\nTheorem 1 The k-consistency closure of a CSP instance P is empty if and only if its direct\\nencoding as a set of clauses has a negative-hyper-resolution refutation of width at most k.\\nThe proof is broken down into two lemmas inspired by Lemmas 2 and 3 in the work\\nof Atserias and Dalmau (2008).\\nLemma 2 Let P be a CSP instance, and let Φ be its direct encoding as a set of clauses.\\nIf Φ has no negative-hyper-resolution refutation of width k or less, then the k-consistency\\nclosure of P is non-empty.\\nProof.\\nLet V be the set of variables of P, where each v ∈ V has domain Dv, and let\\nX = {xvi | v ∈ V, i ∈ Dv} be the corresponding set of Boolean variables in Φ. Let Γ be the\\nset of all clauses having a negative-hyper-resolution derivation from Φ of width at most k.\\nBy the deﬁnition of negative-hyper-resolution, every non-empty clause in Γ consists entirely\\nof negative literals.\\nNow let H be the set of all partial assignments for P with domain size at most k + 1\\nthat do not falsify any clause in Φ ∪ Γ under the direct encoding.\\nConsider any element f ∈ H. By the deﬁnition of H, f does not falsify any clause of\\nΦ, so by the deﬁnition of the direct encoding, every element of H is a partial solution to\\nP. Furthermore, if f extends g, then g is also an element of H, because g makes fewer\\nassignments than f and hence cannot falsify any additional clauses to f.\\nIf Φ has no negative-hyper-resolution refutation of width at most k, then Γ does not\\ncontain the empty clause, so H contains (at least) the partial solution with empty domain,\\nand hence H is not empty.\\nNow let f be any element of H with |Dom(f)| ≤ k and let v be any variable of P\\nthat is not in Dom(f). For any partial assignment g that extends f and has Dom(g) =\\nDom(f) ∪ {v} we have that either g ∈ H or else there exists a clause in Φ ∪ Γ that is\\nfalsiﬁed by g. Since g is a partial assignment, any clause C in Φ ∪ Γ that is falsiﬁed by g,\\nmust consist entirely of negative literals. Hence the literals of C must either be of the form\\n¬xwf(w) for some w ∈ Dom(f), or else ¬xvg(v). Moreover, any such clause must contain the\\nliteral ¬xvg(v), or else it would already be falsiﬁed by f.\\nAssume, for contradiction, that H does not contain any assignment g that extends f and\\nhas Dom(g) = Dom(f) ∪ {v}. In that case, we have that, for each i ∈ Dv, Φ ∪ Γ contains a\\nclause Ci consisting of negative literals of the form ¬xwf(w) for some w ∈ Dom(f), together\\nwith the literal ¬xvi. Now consider the clause, C, which is the negative-hyper-resolvent\\nof these clauses Ci and the at-least-one clause �\\ni∈Dv xvi. The clause C consists entirely\\nof negative literals of the form ¬xwf(w) for some w ∈ Dom(f), so it has width at most\\n|Dom(f)| ≤ k, and hence is an element of Γ. However C is falsiﬁed by f, which contradicts\\nthe choice of f. Hence we have shown that for all f ∈ H with |Dom(f)| ≤ k, and for\\n335\\nJeavons & Petke\\nall variables v such that v ̸∈ Dom(f), there is some g ∈ H such that g extends f and\\nv ∈ Dom(g).\\nWe have shown that H satisﬁes all the conditions required by Lemma 1, so we conclude\\nthat the k-consistency closure of P is non-empty.\\n2\\nLemma 3 Let P be a CSP instance, and let Φ be its direct encoding as a set of clauses.\\nIf the k-consistency closure of P is non-empty, then Φ has no negative-hyper-resolution\\nrefutation of width k or less.\\nProof.\\nLet V be the set of variables of P, where each v ∈ V has domain Dv, and let\\nX = {xvi | v ∈ V, i ∈ Dv} be the corresponding set of Boolean variables in Φ.\\nBy Lemma 1, if the k-consistency closure of P is non-empty, then there exists a non-\\nempty set H of partial solutions to P which satisﬁes the three properties described in\\nLemma 1.\\nNow consider any negative-hyper-resolution derivation Γ from Φ of width at most k. We\\nshow by induction on the length of this derivation that the elements of H do not falsify any\\nclause in the derivation. First we note that the elements of H are partial solutions, so they\\nsatisfy all the constraints of P, and hence do not falsify any clause of Φ. This establishes\\nthe base case. Assume, for induction, that all clauses in the derivation earlier than some\\nclause C are not falsiﬁed by any element of H.\\nNote that, apart from the at-least-one clauses, all clauses in Φ and Γ consist entirely of\\nnegative literals. Hence we may assume, without loss of generality, that C is the negative-\\nhyper-resolvent of a set of clauses ∆ = {Ci ∨ ¬xvi | i ∈ Dv} and the at-least-one clause\\n�\\ni∈Dv xvi, for some ﬁxed variable v.\\nIf f ∈ H falsiﬁes C, then the literals of C must all be of the form ¬xwf(w), for some\\nw ∈ Dom(f). Since the width of the derivation is at most k, C contains at most k literals,\\nand hence we may assume that |Dom(f)| ≤ k. But then, by the choice of H, there must\\nexist some extension g of f in H such that v ∈ Dom(g). Any such g will falsify some\\nclause in ∆, which contradicts our inductive hypothesis. Hence no f ∈ H falsiﬁes C, and,\\nin particular, C cannot be empty.\\nIt follows that no negative-hyper-resolution derivation of width at most k can contain\\nthe empty clause.\\n2\\nNote that the proof of Theorem 1 applies to any sparse encoding that contains the\\nat-least-one clauses for each variable, and where all other clauses are purely negative. We\\nwill call such an encoding a negative sparse encoding. As well as the direct encoding, other\\nnegative sparse encodings exist. For example, we may use negative clauses that involve only\\na subset of the variables in the scope of some constraints (to forbid tuples where all possible\\nextensions to the complete scope are disallowed by the constraint). Another example of\\na negative sparse encoding is a well-known variant of the direct encoding in which the\\nat-most-one clauses are omitted.\\nCorollary 1 The k-consistency closure of a CSP instance P is empty if and only if any\\nnegative sparse encoding of P has a negative-hyper-resolution refutation of width at most k.\\n336\\nLocal Consistency and SAT-Solvers\\n4. Negative-Hyper-Resolution and SAT-Solvers\\nIn this section we adapt the machinery from Atserias et al. (2011), and Pipatsrisawat and\\nDarwiche (2009) to show that for any ﬁxed k, the existence of a negative-hyper-resolution\\nrefutation of width k is likely to be discovered by a SAT-solver in polynomial-time using\\nstandard clause learning and restart techniques, even with a totally random branching\\nstrategy.\\nNote that previous results about the power of clause-learning SAT-solvers have generally\\nassumed an optimal branching strategy (Beame, Kautz, & Sabharwal, 2004; Pipatsrisawat\\n& Darwiche, 2009) - they have shown what solvers are potentially capable of doing, rather\\nthan what they are likely to achieve in practice.\\nAn important exception is the paper\\nby Atserias et al. (2011), which gives an analysis of likely behaviour, but relies on the\\nexistence of a standard resolution proof of bounded width. Here we show that the results\\nof Atserias et al. can be extended to hyper-resolution proofs, which can be shorter and\\nnarrower than their associated standard resolution proofs.\\nWe will make use of the following terminology from Atserias et al. (2011). For a clause\\nC, a Boolean variable x, and a truth value a ∈ {0, 1}, the restriction of C by the assignment\\nx = a, denoted C|x=a, is deﬁned to be the constant 1, if the assignment satisﬁes the clause,\\nor else the clause obtained by deleting from C any literals involving the variable x. For\\nany sequence of assignments S of the form (x1 = a1, x2 = a2, . . . , xr = ar) we write C|S to\\ndenote the result of computing the restriction of C by each assignment in turn. If C|S is\\nempty, then we say that the assignments in S falsify the clause C. For a set of clauses ∆,\\nwe write ∆|S to denote the set {C|S | C ∈ ∆} \\\\ {1}.\\nMost current SAT-solvers operate in the following way (Atserias et al., 2011; Pipat-\\nsrisawat & Darwiche, 2009). They maintain a database of clauses ∆ and a current state\\nS, which is a partial assignment of truth values to the Boolean variables in the clauses of\\n∆. A high-level description of the algorithms used to update the clause database and the\\nstate, derived from the description given in Atserias et al., is shown in Algorithm 1 (a sim-\\nilar framework, using slightly diﬀerent terminology, is given in Pipatsrisawat & Darwiche,\\n2009).\\nNow consider a run of the algorithm shown in Algorithm 1, started with the initial\\ndatabase ∆, and the empty state S0, until it either halts or discovers a conﬂict (i.e., ∅ ∈ ∆|S).\\nSuch a run is called a complete round started with ∆, and we represent it by the sequence\\nof states S0, . . . , Sm, that the algorithm maintains. Note that each state Si extends the\\nstate Si−1 by a single assignment to a Boolean variable, which may be either a decision\\nassignment or an implied assignment.\\nMore generally, a round is an initial segment S0, S1, . . . , Sr of a complete round started\\nwith ∆, up to a state Sr such that either ∆|Sr contains the empty clause, or ∆|Sr does not\\ncontain any unit clause. For any clause C, we say that a round S0, S1, . . . , Sr satisﬁes C if\\nC|Sr = 1, and we say that the round falsiﬁes C if C|Sr is empty.\\nIf S0, S1, . . . , Sr is a round started with ∆, and ∆|Sr contains the empty clause, then\\nthe algorithm either reports unsatisﬁability or learns a new clause: such a round is called\\nconclusive. If a round is not conclusive we call it inconclusive 2. Note that if S0, S1, . . . , Sr\\nis an inconclusive round started with ∆, then ∆|Sr does not contain the empty clause,\\n2. Note that a complete round that assigns all variables and reports satisﬁability is called inconclusive.\\n337\\nJeavons & Petke\\nand does not contain any unit clauses. Hence, for any clause C ∈ ∆, if Sr falsiﬁes all the\\nliterals of C except one, then it must satisfy the remaining literal, and hence satisfy C. This\\nproperty of clauses is captured by the following deﬁnition.\\nDeﬁnition 4 (Atserias et al., 2011) Let ∆ be a set of clauses, C a non-empty clause, and\\nl a literal of C. We say that ∆ absorbs C at l if every inconclusive round started with ∆\\nthat falsiﬁes C \\\\ {l} satisﬁes C.\\nIf ∆ absorbs C at each literal l in C, then we simply say that ∆ absorbs C.\\nNote that a closely related notion is introduced by Pipatsrisawat and Darwiche (2009) for\\nclauses that are not absorbed by a set of clauses ∆; they are referred to as 1-empowering with\\nrespect to ∆. (The exact relationship between 1-empowering and absorption is discussed\\nin Atserias et al., 2011.)\\nWe will now explore the relationship between absorption and negative-hyper-resolution.\\nExample 5 Let ∆ be the direct encoding of a CSP instance P = (V, D, C), where V =\\n{u, v, w}, Du = Dv = Dw = {1, 2} and C contains two binary constraints: one forbids the\\nassignment of the value 1 to u and v simultaneously, and the other forbids the simultaneous\\nassignment of the value 2 to u and 1 to w. Let C also contain a ternary constraint that\\nforbids the assignment of the value 2 to all three variables simultaneously.\\n∆ = { xu1 ∨ xu2, xv1 ∨ xv2, xw1 ∨ xw2,\\n¬xu1 ∨ ¬xu2, ¬xv1 ∨ ¬xv2, ¬xw1 ∨ ¬xw2,\\n¬xu1 ∨ ¬xv1, ¬xu2 ∨ ¬xw1, ¬xu2 ∨ ¬xv2 ∨ ¬xw2 }.\\nThe clause ¬xv1 ∨ ¬xw1 is not contained in ∆, but can be obtained by negative-hyper-\\nresolution from the clauses xu1 ∨ xu2, ¬xu1 ∨ ¬xv1, ¬xu2 ∨ ¬xw1.\\nThis clause is absorbed by ∆, since every inconclusive round that sets xv1 = true must\\nset xw1 = false by unit propagation, and every inconclusive round that sets xw1 = true\\nmust set xv1 = false also by unit propagation.\\nExample 5 indicates that clauses that can be obtained by negative hyper-resolution from a\\nset of clauses ∆ are sometimes absorbed by ∆. The next result clariﬁes when this situation\\nholds.\\nLemma 4 Any negative-hyper-resolvent of a set of disjoint clauses is absorbed by that set\\nof clauses.\\nProof.\\nLet C be the negative-hyper-resolvent of a set of clauses ∆ = {Ci ∨ ¬xi | i =\\n1, 2, . . . , r} and a clause C′ = C0 ∨ x1 ∨ x2 ∨ · · · ∨ xr, where each Ci is a (possibly empty)\\ndisjunction of negative literals, for 0 ≤ i ≤ r. Then C = C0 ∨ C1 ∨ · · · ∨ Cr by Deﬁnition 3.\\nBy Deﬁnition 4, we must show that ∆ ∪ C′ absorbs C at each of its literals. Assume all\\nbut one of the literals of C are falsiﬁed. Since the set of clauses ∆ ∪ C′ are assumed to be\\ndisjoint, the remaining literal l must belong to exactly one of the clauses in this set. There\\nare two cases to consider.\\n1. If l belongs to the clause C′, then all clauses in ∆ have all but one literals falsiﬁed, so\\nthe remaining literal ¬xi in each of these clauses is set to true, by unit propagation.\\nHence all literals in C′ are falsiﬁed, except for l, so l is set to true, by unit propagation.\\n338\\nLocal Consistency and SAT-Solvers\\n2. If l belongs to one of the clauses Ci ∨ ¬xi, then all of the remaining clauses in ∆ have\\nall but one literals falsiﬁed, so the corresponding literals ¬xj are set to true, by unit\\npropagation. Hence all literals in C′ are falsiﬁed, except for xi, so xi is set to true, by\\nunit propagation. But now all literals in Ci ∨ ¬xi are falsiﬁed, except for l, so l is set\\nto true by unit propagation.\\n2\\nThe next example shows that the negative-hyper-resolvent of a set of clauses that is not\\ndisjoint will not necessarily be absorbed by those clauses.\\nExample 6 Recall the set of clauses ∆ given in Example 5, which is the direct encoding of\\na CSP instance with three variables {u, v, w}, each with domain {1, 2}.\\nThe clause ¬xu2 ∨ ¬xv2 is not contained in ∆, but can be obtained by negative-hyper-\\nresolution from the clauses xw1 ∨ xw2, ¬xu2 ∨ ¬xv2 ∨ ¬xw2, ¬xu2 ∨ ¬xw1.\\nThis clause is not absorbed by ∆, since an inconclusive round that sets xv2 = true will\\nnot necessarily ensure that xu2 = false by unit propagation.\\nThe basic approach we shall use to establish our main results below is to show that any\\nclauses that can be obtained by bounded width negative-hyper-resolution from a given set\\nof clauses, but are not immediately absorbed (such as the one in Example 6) are likely\\nto become absorbed quite quickly because of the additional clauses that are added by\\nthe process of clause learning. Hence a clause-learning SAT-solver is likely to fairly rapidly\\nabsorb all of the clauses that can be derived from its original database of clauses by negative-\\nhyper-resolution.\\nIn particular, if the empty clause can be derived by negative-hyper-\\nresolution, then the solver will fairly rapidly absorb some literal and its complement, and\\nhence report unsatisﬁability (see the proof of Theorem 2 for details).\\nThe following key properties of absorption are established by Atserias et al. (2011).\\nLemma 5 (Atserias et al., 2011) Let ∆ and ∆′ be sets of clauses, and let C and C′ be\\nnon-empty clauses.\\n1. If C belongs to ∆, then ∆ absorbs C;\\n2. If C ⊆ C′ and ∆ absorbs C, then ∆ absorbs C′;\\n3. If ∆ ⊆ ∆′ and ∆ absorbs C, then ∆′ absorbs C.\\nTo allow further analysis, we need to make some assumptions about the learning scheme,\\nthe restart policy and the branching strategy used by our SAT-solver.\\nThe learning scheme is a rule that creates and adds a new clause to the database\\nwhenever there is a conﬂict. Such a clause is called a conﬂict clause, and each of its literals\\nis falsiﬁed by some assignment in the current state. If a literal is falsiﬁed by the i-th decision\\nassignment, or some later implied assignment before the (i+1)-th decision assignment, it is\\nsaid to be falsiﬁed at level i. If a conﬂict clause contains exactly one literal that is falsiﬁed\\nat the maximum possible level, it is called an asserting clause (Pipatsrisawat & Darwiche,\\n2009; Zhang, Madigan, Moskewicz, & Malik, 2001).\\nAssumption 1 The learning scheme chooses an asserting clause.\\n339\\nJeavons & Petke\\nAlgorithm 1 Framework for a typical clause-learning SAT-solver\\nInput: ∆ : set of clauses;\\nS : partial assignment of truth values to variables.\\n1. while ∆|S ̸= ∅ do\\n2.\\nif ∅ ∈ ∆|S then\\nConflict\\n3.\\nif S contains no decision assignments then\\n4.\\nprint “UNSATISFIABLE” and halt\\n5.\\nelse\\n6.\\napply the learning scheme to add a new clause to ∆\\n7.\\nif restart policy says restart then\\n8.\\nset S = ∅\\n9.\\nelse\\n10.\\nselect most recent conﬂict-causing unreversed decision assignment in S\\n11.\\nreverse this decision, and remove all later assignments from S\\n12.\\nend if\\n13.\\nend if\\n14.\\nelse if {l} ∈ ∆|S for some literal l then\\nUnit Propagation\\n15.\\nadd to S the implied assignment x = a which satisﬁes l\\n16.\\nelse\\nDecision\\n17.\\napply the branching strategy to choose a decision assignment x = a\\n18.\\nadd this decision assignment to S\\n19.\\nend if\\n20. end while\\n21. print “SATISFIABLE” and output S\\nMost learning schemes in current use satisfy this assumption (Pipatsrisawat & Dar-\\nwiche, 2009; Zhang et al., 2001), including the learning schemes called “1UIP” and “De-\\ncision” (Zhang et al., 2001).\\nWe make no particular assumption about the restart policy. However, our main result\\nis phrased in terms of a bound on the expected number of restarts. If the algorithm restarts\\nafter r conﬂicts, our bound on the expected number of restarts can simply be multiplied\\nby r to get a bound on the expected number of conﬂicts.\\nThis means that the results\\nwill be strongest if the algorithm restarts immediately after each conﬂict. In that case,\\nr = 1 and our bound will also bound the expected number of conﬂicts. Existing SAT-\\nsolvers typically do not employ such an aggressive restart policy, but we note the remark\\nin the work of Pipatsrisawat and Darwiche (2009, p.666) that “there has been a clear trend\\ntowards more and more frequent restarts for modern SAT solvers”.\\nThe branching strategy determines which decision assignment is chosen after an incon-\\nclusive round that is not complete. In most current SAT solvers the strategy is based on\\nsome heuristic measure of variable activity, which is related to the occurrence of a variable in\\nconﬂict clauses (Moskewicz, Madigan, Zhao, Zhang, & Malik, 2001). However, to simplify\\nthe probabilistic analysis, we will make the following assumption.\\n340\\nLocal Consistency and SAT-Solvers\\nAssumption 2 The branching strategy chooses a variable uniformly at random amongst\\nthe unassigned variables, and assigns it the value TRUE.\\nAs noted by Atserias et al. (2011), the same analysis we give below can also be applied\\nto any other branching strategy that randomly chooses between making a heuristic-based\\ndecision or a randomly-based decision. More precisely, if we allow, say, c > 1 rounds of non-\\nrandom decisions between random ones, then the number of required restarts and conﬂicts\\nwould appear multiplied by a factor of c.\\nAn algorithm that behaves according to the description in Algorithm 1, and satisﬁes\\nthe assumptions above, will be called a standard randomised SAT-solver.\\nTheorem 2 If a set of non-empty clauses ∆ over n Boolean variables has a negative-\\nhyper-resolution refutation of width k and length m, then the expected number of restarts\\nrequired by a standard randomised SAT-solver to discover that ∆ is unsatisﬁable is less than\\nmnk2�n\\nk\\n�.\\nProof. Let C1, C2, . . . , Cm be a negative-hyper-resolution refutation of width k from ∆,\\nwhere Cm is the ﬁrst occurrence of the empty clause. Since each clause in ∆ is non-empty,\\nCm must be derived by negative-hyper-resolution from some collection of negative literals\\n¬x1, ¬x2, . . . ¬xd and a purely positive clause x1 ∨ x2 ∨ · · · ∨ xd ∈ ∆.\\nNow consider a standard randomised SAT-solver started with database ∆. Once all of\\nthe unit clauses ¬xi are absorbed by the current database, then, by Deﬁnition 4, any further\\ninconclusive round of the algorithm must assign all variables xi false, and hence falsify the\\nclause x1 ∨x2 ∨· · · xd. Since this happens even when no decision assignments are made, the\\nSAT-solver will report unsatisﬁability.\\nIt only remains to bound the expected number of restarts required until each clause\\nCi is absorbed, for 1 ≤ i < m. Let each Ci be the negative-hyper-resolvent of clauses\\nCi1, Ci2, . . . , Cir, each of the form C′\\nij∨¬xj, together with a clause Ci0 = C0∨x1∨x2∨· · ·∨xr\\nfrom ∆, where C0 is a (possibly empty) disjunction of negative literals. Assume also that\\neach clause Cij is absorbed by ∆ for j = 0, 1, . . . , r.\\nIf ∆ absorbs Ci, then no further learning or restarts are needed, so assume now that ∆\\ndoes not absorb Ci. By Deﬁnition 4, this means that there exists some literal l and some\\ninconclusive round R started with ∆ that falsiﬁes Ci \\\\ {l} and does not satisfy Ci. Note\\nthat R must leave the literal l unassigned, because one assignment would satisfy Ci and\\nthe other would falsify C0 and each C′\\nij, and hence force all of the literals ¬xj used in the\\nnegative-hyper-resolution step to be satisﬁed, because each Cij is absorbed by ∆, so Ci0\\nwould be falsiﬁed, contradicting the fact that R is inconclusive.\\nHence, if the branching strategy chooses to falsify the literals Ci \\\\ {l} whenever it has\\na choice, it will construct an inconclusive round R′ where l is unassigned (since all the\\ndecision assignments in R′ are also assigned the same values in R, any implied assignments\\nin R′ must also be assigned the same values3 in R, but we have shown that R leaves l\\nunassigned). If the branching strategy then chooses to falsify the remaining literal l of Ci,\\nthen the algorithm would construct a conclusive round R′′ where Ci0 is falsiﬁed, and all\\n3. See Lemmas 5, 8 and 10 in the work of Atserias et al. (2011) for a more formal statement and proof of\\nthis assertion.\\n341\\nJeavons & Petke\\ndecision assignments falsify literals in Ci. Hence, by Assumption 1, the algorithm would\\nthen learn some asserting clause C′ and add it to ∆ to obtain a new set ∆′.\\nSince C′ is an asserting clause, it contains exactly one literal, l′, that is falsiﬁed at the\\nhighest level in R′′. Hence, any inconclusive round R started with ∆′ that falsiﬁes Ci \\\\ {l}\\nwill falsify all but one literal of C′, and hence force the remaining literal l′ to be satisﬁed,\\nby unit propagation. If this new implied assignment for l′ propagates to force l to be true,\\nthen R satisﬁes Ci, and hence ∆′ absorbs Ci at l. If not, then the branching strategy can\\nonce again choose to falsify the remaining literal l of Ci, which will cause a new asserting\\nclause to be learned and added to ∆. Since each new asserting clause forces a new literal to\\nbe satisﬁed after falsifying Ci \\\\ {l} this process can be repeated fewer than n times before\\nit is certain that ∆′ absorbs Ci at l.\\nNow consider any sequence of k random branching choices. If the ﬁrst k − 1 of these\\neach falsify a literal of Ci \\\\ {l}, and the ﬁnal choice falsiﬁes l, then we have shown that the\\nassociated round will reach a conﬂict, and add an asserting clause to ∆. With a random\\nbranching strategy, as described in Assumption 2, the probability that this happens is at\\nleast the probability that the ﬁrst k − 1 random choices consist of a ﬁxed set of variables\\n(in some order), and the ﬁnal choice is the variable associated with l.\\nThe number of\\nrandom choices that fall in a ﬁxed set follows the hypergeometric distribution, so the overall\\nprobability of this is\\n1\\n( n\\nk−1)\\n1\\n(n−k+1) = 1/(k\\n�n\\nk\\n�).\\nTo obtain an upper bound on the expected number of restarts, consider the worst case\\nwhere we require n asserting clauses to be added to absorb each clause Ci at each of its k\\nliterals l. Since we require only an upper bound, we will treat each round as an independent\\ntrial with success probability p = 1/(k\\n�n\\nk\\n�), and consider the worst case where we have to\\nachieve (m − 1)nk successes to ensure that Ci for 1 ≤ i < m is absorbed. In this case the\\ntotal number of restarts will follow a negative binomial distribution, with expected value\\n(m − 1)nk/p. Hence in all cases the expected number of restarts is less than mnk2�n\\nk\\n�.\\n2\\nA tighter bound on the number of restarts can be obtained if we focus on the Decision\\nlearning scheme (Atserias et al., 2011; Zhang et al., 2001), as the next result indicates.\\nTheorem 3 If a set of non-empty clauses ∆ over n Boolean variables has a negative-hyper-\\nresolution refutation of width k and length m, then the expected number of restarts required\\nby a standard randomised SAT-solver using the Decision learning scheme to discover that\\n∆ is unsatisﬁable is less than m\\n�n\\nk\\n�.\\nProof. The proof is similar to the proof of Theorem 2, except that the Decision learn-\\ning scheme has the additional feature that the literals in the chosen conﬂict clause falsify a\\nsubset of the current decision assignments. Hence in the situation we consider, where the\\ndecision assignments all falsify literals of some clause Ci, this learning scheme will learn a\\nsubset of Ci, and hence immediately absorb Ci, by Lemma 5 (1,2). Hence the maximum\\nnumber of learnt clauses required is reduced from (m−1)nk to (m−1), and the probability\\nis increased from 1/(k\\n�n\\nk\\n�) to 1/\\n�n\\nk\\n�, giving the tighter bound.\\n2\\nNote that a similar argument shows that the standard deviation of the number of restarts\\nis less than the standard deviation of a negative binomial distribution with parameters m\\n342\\nLocal Consistency and SAT-Solvers\\nand 1/\\n�n\\nk\\n�, which is less than √m\\n�n\\nk\\n�. Hence, by Chebyshev’s inequality (one-tailed version),\\nthe probability that a standard randomised SAT-solver using the decision learning scheme\\nwill discover that ∆ is unsatisﬁable after (m + √m)\\n�n\\nk\\n� restarts is greater than 1/2.\\n5. k-Consistency and SAT-Solvers\\nBy combining Theorem 1 and Theorem 3 we obtain the following result linking k-consistency\\nand SAT-solvers.\\nTheorem 4 If the k-consistency closure of a CSP instance P is empty, then the expected\\nnumber of restarts required by a standard randomised SAT-solver using the Decision learn-\\ning scheme to discover that the direct encoding of P is unsatisﬁable is O(n2kd2k), where n\\nis the number of variables in P and d is the maximum domain size.\\nProof. The length m of a negative-hyper-resolution refutation of width k is bounded\\nby the number of possible no-goods of length at most k for P, which is �k\\ni=1 di�n\\ni\\n�. Hence,\\nby Theorem 1 and Theorem 3 we obtain a bound of\\n��k\\ni=1 di�n\\ni\\n�� �nd\\nk\\n�, which is O(n2kd2k). 2\\nHence a standard randomised SAT-solver with a suitable learning strategy will decide\\nthe satisﬁability of any CSP instance with tree-width k with O(n2kd2k) expected restarts,\\neven when it is set to restart immediately after each conﬂict. In particular, the satisﬁability\\nof any tree-structured binary CSP instance (i.e., with tree-width 1) will be decided by such\\na solver with at most O(n2d2) expected conﬂicts, which is comparable with the growth rate\\nof an optimal arc-consistency algorithm for binary constraints. Note that this result cannot\\nbe obtained directly from the work of Atserias et al. (2011), because the direct encoding of\\nan instance with tree-width k is a set of clauses whose tree-width may be as high as dk.\\nMoreover, a standard randomised SAT-solver will decide the satisﬁability of any CSP\\ninstance, with any structure, within the same polynomial bounds, if the constraint relations\\nsatisfy certain algebraic properties that ensure bounded width (Barto & Kozik, 2009).\\nExamples of such constraint types include the “0/1/all” relations, deﬁned by Cooper et al.\\n(1994), and the “connected row-convex” relations, deﬁned by Deville et al. (1997), which\\ncan both be decided by 2-consistency.\\nIt was shown by Gent (2002) that the support encoding of a binary CSP instance can\\nbe made arc-consistent (that is, 1-consistent) by applying unit propagation alone. Hence, a\\nstandard SAT-solver will mimic the eﬀect of enforcing arc-consistency on such an encoding\\nbefore making any decisions or restarts. By combining Theorem 4 with the observation in\\nExample 4 that the direct encoding can be obtained from the support encoding by negative-\\nhyper-resolution, we obtain the following corollary concerning the support encoding for all\\nhigher levels of consistency.\\nCorollary 2 For any k ≥ 2, if the k-consistency closure of a binary CSP instance P\\nis empty, then the expected number of restarts required by a standard randomised SAT-\\nsolver using the Decision learning scheme to discover that the support encoding of P is\\nunsatisﬁable is O(n2kd2k), where n is the number of variables in P and d is the maximum\\ndomain size.\\n343\\nJeavons & Petke\\nThe CSP literature describes many variations on the notion of consistency.\\nIn this\\npaper we have considered k-consistency only. We note that our results can be generalised\\nto some other types of consistency such as singleton arc-consistency (Bessi`ere, 2006). The\\nextension to singleton arc-consistency follows from the recent discovery that if a family of\\nCSP instances is solvable by enforcing singleton arc-consistency, then the instances have\\nbounded width (Chen, Dalmau, & Grußien, 2011). In other words, all such instances can\\nbe solved by enforcing k-consistency, for some ﬁxed k. Hence, by Theorem 4, they will be\\nsolved in polynomial expected time by a standard randomised SAT-solver.\\n6. Experimental Results\\nThe polynomial upper bounds we obtain in this paper are not asymptotic, they apply for\\nall values of n, m and k. However, they are very conservative, and are likely to be met very\\neasily in practice.\\nTo investigate how an existing SAT-solver actually performs, we measured the runtime\\nof the MiniSAT solver (E´en & S¨orensson, 2003), version 2.2.0, on a family of CSP instances\\nthat can be decided by a ﬁxed level of consistency. For comparison, we also ran our ex-\\nperiments on two state-of-the-art constraint solvers: we used Minion (Gent, Jeﬀerson, &\\nMiguel, 2006), version 0.12, and the G12 ﬁnite domain solver (Nethercote et al., 2007),\\nversion 1.4.\\nTo match the simpliﬁed assumptions of our analysis more closely, we ran a further\\nset of experiments on a core version of MiniSAT in order to get a solver that uses only\\nunit propagation and conﬂict-directed learning with restarts. We also modiﬁed the solver to\\nfollow the random branching strategy described above. Our solver does not delete any learnt\\nclauses and uses an extreme restart policy that makes it restart whenever it encounters a\\nconﬂict. It uses the same learning scheme as MiniSAT. We refer to this modiﬁed solver as\\nsimple-MiniSAT.\\nAs the characteristic feature of the instances tested is their relatively low tree-width,\\nwe also used the Toulbar2 solver (Sanchez et al., 2008). This solver implements the BTD\\n(Backtracking with Tree-Decomposition) technique which has been shown to be eﬃcient\\nin practice, in contrast to earlier methods that had been proposed to attempt to exploit\\ntree-decompositions of the input problem (J´egou & Terrioux, 2003). As the problem of\\nﬁnding a tree-decomposition of minimal width (i.e., the tree-width) is NP-hard, the BTD\\ntechnique uses some approximations (described in J´egou & Terrioux, 2003). We note here\\nthat Toulbar2 is designed for solving optimization problems, namely weighted CSPs, or\\nWCSPs. In a WCSP instance, certain partial assignments have an associated cost. However,\\nthe Toulbar2 solver can be used to solve standard CSPs by simply setting all costs to 0.\\nFor all of the results, the times given are elapsed times on a Lenovo 3000 N200 laptop\\nwith an Intel Core 2 Duo processor running at 1.66GHz with 2GB of RAM. Each generated\\ninstance was run ﬁve times and the mean times and mean number of restarts are shown4.\\nExample 7 We consider a family of instances speciﬁed by two parameters, w and d. They\\nhave ((d−1)∗w+2)∗w variables arranged in groups of size w, each with domain {0, ..., d−1}.\\n4. MiniSAT and simple-MiniSAT were run with diﬀerent seeds for each of the ﬁve runs of an instance.\\nInstances marked with * were run once only.\\nThe runtime of simple-MiniSAT on those instances\\nexceeded 6 hours. Moreover, Toulbar2 was run with parameter B = 1 which enables BTD.\\n344\\nLocal Consistency and SAT-Solvers\\nWe impose a constraint of arity 2w on each pair of successive groups, requiring that the\\nsum of the values assigned to the ﬁrst of these two groups should be strictly smaller than\\nthe sum of the values assigned to the second. This ensures that the instances generated are\\nunsatisﬁable. An instance with w = 2 and d = 2 is shown diagrammatically and deﬁned\\nusing the speciﬁcation language MiniZinc (Nethercote et al., 2007) in Figure 1 (a) and (b)\\nrespectively5. A similar format is used for Toulbar2 6 and the same instance encoded in\\nthis format is shown in Figure 1 (c) (note that each hard constraint has cost 0).\\n(a) Graphical representation.\\narray[1..4] of var 0..1 : X1;\\narray[1..4] of var 0..1 : X2;\\nconstraint\\nforall(i in 1..3)(\\nX1[i] + X2[i] < X1[i + 1] + X2[i + 1]);\\nsolve satisfy;\\n(b) Speciﬁcation in MiniZinc.\\nchain\\nx1 0 1\\nx2 0 1\\nx3 0 1\\nx4 0 1\\nx5 0 1\\nx6 0 1\\nx7 0 1\\nx8 0 1\\nhard( x1 + x2 < x3 + x4 )\\nhard( x3 + x4 < x5 + x6 )\\nhard( x5 + x6 < x7 + x8 )\\n(c) Speciﬁcation in cp format.\\nFigure 1: An example of a CSP instance with w = 2, d = 2 and tree-width = 3.\\nThe structure of the instances described in Example 7 has a simple tree-decomposition as a\\npath of nodes, with each node corresponding to a constraint scope. Hence the tree-width of\\nthese instances is 2w − 1 and they can be shown to be unsatisﬁable by enforcing (2w − 1)-\\nconsistency (Atserias et al., 2007). However, these instances cannot be solved eﬃciently\\nusing standard propagation algorithms which only prune individual domain values.\\nThe structure of the direct encoding of these instances also has a tree-decomposition\\nwith each node corresponding to a constraint scope in the original CSP instance. However,\\nbecause the direct encoding introduces d Boolean variables to represent each variable in the\\n5. In order to run an instance on a CP solver one must usually use a translator to convert the original\\nmodel. The MiniZinc distribution provides an mzn2fzn translator while for Minion one can use Tailor\\n(available at http://www.cs.st-andrews.ac.uk/∼andrea/tailor/).\\n6. A\\ncp2wcsp\\ntranslator\\nand\\na\\ndescription\\nof\\nthe\\ncp\\nand\\nwcsp\\nformats\\nis\\navailable\\nat\\nhttp://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/SoftCSP.\\n345\\nJeavons & Petke\\noriginal instance, the tree-width of the encoded SAT instances is larger by approximately a\\nfactor of d; it is in fact 2wd − 1 (see Figure 2).\\n(a) Tree-decomposition of the origi-\\nnal instance.\\n(b) Tree-decomposition of its direct\\nencoding.\\nFigure 2: Tree-decompositions of the CSP instance from Figure 1.\\nTable 1 shows the runtimes of simple-MiniSAT and the original MiniSAT solver on\\nthis family of instances, along with times for the two state-of-the-art CP solvers and the\\nWCSP solver Toulbar2. By far the best solver for this set of instances is Toulbar2,\\nwhich is explicitly designed to exploit low tree-width by constructing a tree-decomposition.\\nFor the class of instances we are considering, the widths of the tree-decompositions found\\nby Toulbar2 matched the tree-widths of the instances tested (i.e., 2w − 1).\\nHowever, we also note that MiniSAT is remarkably eﬀective in solving these chains\\nof inequalities, compared to Minion and G12, even though the use of MiniSAT requires\\nencoding each instance into a large number of clauses with a much larger tree-width than\\nthe original. Although our simpliﬁed version of the MiniSAT solver takes a little longer\\nthan the current highly optimised version, it still performs very well on these instances in\\ncomparison with the conventional CP solvers. Moreover, the number of restarts (and hence\\nthe number of conﬂicts) appears to grow only polynomially with the size of the instance\\n(see Figure 3). In all cases the actual number of restarts is much lower than the polynomial\\nupper bound on the expected number of restarts given in Theorem 4.\\nOur best theoretical upper bounds on the expected run-time were obtained for the\\nDecision learning scheme (Theorem 4), but the standard version of MiniSAT uses the\\n1UIP learning scheme with conﬂict clause minimization.\\nTo allow a direct comparison\\nwith these theoretical upper bounds, we implemented the Decision scheme in simple-\\nMiniSAT. As the 1UIP learning scheme has generally been found to be more eﬃcient\\nin practice (Zhang et al., 2001), we switched oﬀ conﬂict clause minimization in simple-\\nMiniSAT in order to compare the two standard learning schemes and ran a further set of\\nexperiments. We counted the number of restarts for these two modiﬁed solvers on instances\\nof the form described in Example 7 - see Table 2.\\n346\\nLocal Consistency and SAT-Solvers\\ngroup\\ndomain\\nCSP\\nMinion\\nG12\\nToulbar2\\nMiniSAT\\nsimple-\\nsimple-\\nsize\\nsize\\nvariables\\nMiniSAT\\nMiniSAT\\n(w)\\n(d)\\n(n)\\n(sec)\\n(sec)\\n(sec)\\n(sec)\\n(sec)\\nrestarts\\n2\\n2\\n8\\n0.055\\n0.010\\n0.021\\n0.003\\n0.002\\n19\\n2\\n3\\n12\\n0.053\\n0.011\\n0.023\\n0.005\\n0.007\\n157\\n2\\n4\\n16\\n0.057\\n0.013\\n0.040\\n0.015\\n0.034\\n820\\n2\\n5\\n20\\n0.084\\n0.047\\n0.091\\n0.043\\n0.188\\n3 039\\n2\\n6\\n24\\n1.048\\n0.959\\n0.199\\n0.126\\n0.789\\n7 797\\n2\\n7\\n28\\n47.295\\n122.468\\n0.549\\n0.362\\n2.884\\n17 599\\n2\\n8\\n32\\n> 20 min\\n> 20 min\\n1.214\\n0.895\\n9.878\\n36 108\\n2\\n9\\n36\\n> 20 min\\n> 20 min\\n2.523\\n2.407\\n34.352\\n65 318\\n2\\n10\\n40\\n> 20 min\\n> 20 min\\n4.930\\n5.656\\n111.912\\n114 827\\n3\\n2\\n15\\n0.055\\n0.010\\n0.024\\n0.004\\n0.008\\n167\\n3\\n3\\n24\\n0.412\\n0.034\\n0.103\\n0.066\\n0.503\\n5 039\\n3\\n4\\n33\\n> 20 min\\n7.147\\n0.860\\n1.334\\n20.054\\n41 478\\n3\\n5\\n42\\n> 20 min\\n> 20 min\\n5.646\\n20.984\\n817.779\\n210 298\\n3\\n6\\n51\\n> 20 min\\n> 20 min\\n28.663\\n383.564\\n> 20 min\\n731 860\\n4\\n2\\n24\\n0.060\\n0.015\\n0.046\\n0.012\\n0.118\\n1 617\\n4\\n3\\n40\\n> 20 min\\n11.523\\n1.246\\n4.631\\n260.656\\n108 113\\n4\\n4\\n56\\n> 20 min\\n> 20 min\\n20.700\\n1,160.873\\n> 20 min\\n1 322 784*\\nTable 1: Average performance of solvers on instances from Example 7.\\ngroup\\ndomain\\nCSP\\nno. of clauses\\nsimple-\\nsimple-\\nsimple-\\nsimple-\\nsize\\nsize\\nvariables\\nin the direct\\nMiniSAT\\nMiniSAT\\nMiniSAT\\nMiniSAT\\n(w)\\n(d)\\n(n)\\nencoding\\n1UIP\\n1UIP\\nDecision\\nDecision\\n(sec)\\nrestarts\\n(sec)\\nrestarts\\n2\\n2\\n8\\n49\\n0.002\\n21\\n0.002\\n23\\n2\\n3\\n12\\n298\\n0.008\\n203\\n0.010\\n267\\n2\\n4\\n16\\n1 162\\n0.048\\n1 026\\n0.057\\n1 424\\n2\\n5\\n20\\n3 415\\n0.272\\n4 068\\n0.323\\n5 283\\n2\\n6\\n24\\n8 315\\n1.399\\n12 029\\n1.526\\n14 104\\n2\\n7\\n28\\n17 724\\n5.780\\n27 356\\n6.035\\n33 621\\n2\\n8\\n32\\n34 228\\n24.417\\n56 193\\n20.436\\n64 262\\n2\\n9\\n36\\n61 257\\n95.278\\n109 862\\n69.144\\n113 460\\n2\\n10\\n40\\n103 205\\n309.980\\n199 399\\n207.342\\n190 063\\n3\\n2\\n15\\n198\\n0.009\\n192\\n0.012\\n287\\n3\\n3\\n24\\n3 141\\n0.643\\n5 952\\n0.750\\n7 308\\n3\\n4\\n33\\n23 611\\n53.067\\n63 952\\n71.778\\n91 283\\n3\\n5\\n42\\n113 406\\n2,266.627\\n375 849\\n2,036.456\\n391,664\\n3\\n6\\n51\\n408 720\\n> 6 hours\\n1 584 012*\\n> 6 hours\\n1 365 481*\\n4\\n2\\n24\\n863\\n0.141\\n1 937\\n0.192\\n2 592\\n4\\n3\\n40\\n34 666\\n603.241\\n155 842\\n938.836\\n253 153\\nTable 2: Average performance of simple-MiniSAT with the 1UIP and the Decision learn-\\ning schemes on instances from Example 7.\\n347\\nJeavons & Petke\\nFigure 3: Log-log plot of the number of restarts/conﬂicts used by simple-MiniSAT on the\\ninstances from Example 7. The solid lines show a growth function of d2w−2�nd/w\\n3\\n�,\\nwhere n is the number of CSP variables. This empirically derived polynomial\\nfunction appears to ﬁt the experimental data well, and is much lower than the\\nupper bound on the expected number of restarts calculated in Theorem 4 which\\nis O(d4w−2n4w−2).\\n348\\nLocal Consistency and SAT-Solvers\\nAlthough the performance of simple-MiniSAT with the Decision learning scheme\\nand the 1UIP scheme are signiﬁcantly worse than the performance of the original simple-\\nMiniSAT solver, only about twice as many restarts were required for each instance. Hence,\\nour theoretical upper bounds are still easily met for both of these standard learning schemes.\\n7. Conclusions\\nWe have shown that the notion of k-consistency can be precisely captured by a single\\ninference rule on the direct encoding of a CSP instance, restricted to deriving only clauses\\nwith at most k literals. We used this to show that a clause-learning SAT-solver with a purely\\nrandom branching strategy will simulate the eﬀect of enforcing k-consistency in expected\\npolynomial time, for all ﬁxed k. This is suﬃcient to ensure that such solvers are able to\\nsolve certain problem families much more eﬃciently than conventional CP solvers relying\\non GAC-propagation.\\nIn principle clause-learning SAT-solvers can also do much more. It is known that, with\\nan appropriate branching strategy and restart policy, they are able to p-simulate general\\nresolution (Beame et al., 2004; Pipatsrisawat & Darwiche, 2009), and general resolution\\nproofs can be exponentially shorter than the negative-hyper-resolution proofs we have con-\\nsidered here (Hwang & Mitchell, 2005). In practice, it seems that current clause-learning\\nSAT-solvers with highly-tuned learning schemes, branching strategies and restart policies\\nare often able to exploit structure in the Boolean encoding of a CSP instance even more\\neﬀectively than local consistency techniques. Hence considerable work remains to be done\\nin understanding the relevant features of instances which they are able to exploit, in order\\nto predict their eﬀectiveness in solving diﬀerent kinds of CSP instances.\\nAcknowledgments\\nWe would like to thank Albert Atserias and Marc Thurley for comments on the conference\\nversion of this paper, as well as the anonymous referees.\\nThe provision of an EPSRC\\nDoctoral Training Award to Justyna Petke is also gratefully acknowledged.\\nA preliminary version of this paper appeared in Proceedings of the 16th International\\nConference on Principles and Practice of Constraint Programming - CP2010.\\nReferences\\nAtserias, A., Bulatov, A. A., & Dalmau, V. (2007). On the power of k-consistency. In\\nInternational Colloquium on Automata, Languages and Programming - ICALP’07,\\npp. 279–290.\\nAtserias, A., & Dalmau, V. (2008). A combinatorial characterization of resolution width.\\nJournal of Computer and System Sciences, 74(3), 323–334.\\nAtserias, A., Fichte, J. K., & Thurley, M. (2011). Clause-learning algorithms with many\\nrestarts and bounded-width resolution.\\nJournal of Artiﬁcial Intelligence Research\\n(JAIR), 40, 353–373.\\nBacchus, F. (2007). GAC via unit propagation. In Principles and Practice of Constraint\\nProgramming - CP’07, pp. 133–147.\\n349\\nJeavons & Petke\\nBarto, L., & Kozik, M. (2009). Constraint satisfaction problems of bounded width. In\\nSymposium on Foundations of Computer Science - FOCS’09, pp. 595–603.\\nBeame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding and harnessing\\nthe potential of clause learning. Journal of Artiﬁcial Intelligence Research (JAIR),\\n22, 319–351.\\nBessi`ere, C. (2006). Constraint propagation. In Rossi, F., van Beek, P., & Walsh, T. (Eds.),\\nHandbook of Constraint Programming, chap. 3. Elsevier.\\nB¨uning, H., & Lettmann, T. (1999). Propositional logic: deduction and algorithms. Cam-\\nbridge tracts in theoretical computer science. Cambridge University Press.\\nChen, H., Dalmau, V., & Grußien, B. (2011). Arc consistency and friends. Computing\\nResearch Repository - CoRR, abs/1104.4993.\\nCooper, M. C. (1989). An optimal k-consistency algorithm. Artiﬁcial Intelligence, 41(1),\\n89–95.\\nCooper, M. C., Cohen, D. A., & Jeavons, P. (1994). Characterising tractable constraints.\\nArtiﬁcial Intelligence, 65(2), 347–361.\\nde Kleer, J. (1989). A comparison of ATMS and CSP techniques. In International Joint\\nConference on Artiﬁcial Intelligence - IJCAI’89, pp. 290–296.\\nDeville, Y., Barette, O., & Hentenryck, P. V. (1997). Constraint satisfaction over connected\\nrow convex constraints. In International Joint Conference on Artiﬁcial Intelligence -\\nIJCAI’97 (1), pp. 405–411.\\nE´en, N., & S¨orensson, N. (2003). An extensible SAT-solver. In Theory and Applications of\\nSatisﬁability Testing - SAT’03, pp. 502–518.\\nFreuder, E. C. (1978). Synthesizing constraint expressions. Communications of the ACM,\\n21(11), 958–966.\\nGent, I. P. (2002). Arc consistency in SAT. In European Conference on Artiﬁcial Intelligence\\n- ECAI’02, pp. 121–125.\\nGent, I. P., Jeﬀerson, C., & Miguel, I. (2006). Minion: A fast scalable constraint solver. In\\nEuropean Conference on Artiﬁcial Intelligence - ECAI’06, pp. 98–102.\\nHooker, J. N. (2006). Integrated Methods for Optimization (International Series in Oper-\\nations Research & Management Science). Springer-Verlag New York, Inc., Secaucus,\\nNJ, USA.\\nHoos, H. H. (1999). SAT-encodings, search space structure, and local search performance.\\nIn International Joint Conference on Artiﬁcial Intelligence - IJCAI’99, pp. 296–303.\\nHwang, J., & Mitchell, D. G. (2005). 2-way vs. d-way branching for CSP. In Principles and\\nPractice of Constraint Programming - CP’05, pp. 343–357.\\nJ´egou, P., & Terrioux, C. (2003). Hybrid backtracking bounded by tree-decomposition of\\nconstraint networks. Artiﬁcial Intelligence, 146(1), 43–75.\\nKolaitis, P. G., & Vardi, M. Y. (2000). A game-theoretic approach to constraint satisfac-\\ntion. In Conference on Artiﬁcial Intelligence - AAAI’00 / Innovative Applications of\\nArtiﬁcial Intelligence Conference - IAAI’00, pp. 175–181.\\n350\\nLocal Consistency and SAT-Solvers\\nMackworth, A. K. (1977). Consistency in networks of relations. Artiﬁcial Intelligence, 8(1),\\n99–118.\\nMontanari, U. (1974). Networks of constraints: Fundamental properties and applications to\\npicture processing. Information Sciences, 7, 95–132.\\nMoskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaﬀ: En-\\ngineering an eﬃcient SAT solver. In Design Automation Conference - DAC’01, pp.\\n530–535.\\nNethercote, N., Stuckey, P. J., Becket, R., Brand, S., Duck, G. J., & Tack, G. (2007).\\nMiniZinc: Towards a standard CP modelling language. In Principles and Practice of\\nConstraint Programming - CP’07, pp. 529–543.\\nPetke, J., & Jeavons, P. (2009). Tractable benchmarks for constraint programming. Tech-\\nnical Report RR-09-07, Department of Computer Science, University of Oxford.\\nPipatsrisawat, K., & Darwiche, A. (2009). On the power of clause-learning SAT solvers with\\nrestarts. In Principles and Practice of Constraint Programming - CP’09, pp. 654–668.\\nPrestwich, S. D. (2009). CNF encodings. In Biere, A., Heule, M., van Maaren, H., & Walsh,\\nT. (Eds.), Handbook of Satisﬁability, pp. 75–97. IOS Press.\\nRish, I., & Dechter, R. (2000). Resolution versus search: Two strategies for SAT. Journal\\nof Automated Reasoning, 24(1/2), 225–275.\\nRobinson, J. A. (1965). A machine-oriented logic based on the resolution principle. Journal\\nof the ACM, 12(1), 23–41.\\nSanchez, M., Bouveret, S., de Givry, S., Heras, F., J´egou, P., Larrosa, J., Ndiaye, S., Rollon,\\nE., Schiex, T., Terrioux, C., Verfaillie, G., & Zytnicki, M. (2008). Max-CSP compe-\\ntition 2008: Toulbar2 solver description. In Proceedings of the Third International\\nCSP Solver Competition.\\nSchiex, T., & Verfaillie, G. (1993). Nogood recording for static and dynamic constraint\\nsatisfaction problems. In International Conference on Tools with Artiﬁcial Intelligence\\n- ICTAI’93, pp. 48–55.\\nTamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling ﬁnite linear CSP\\ninto SAT. Constraints, 14(2), 254–272.\\nvan Dongen, M., Lecoutre, C., & Roussel, O. (2008). 3rd international CSP solver competi-\\ntion. Instances and results available at http://www.cril.univ-artois.fr/CPAI08/.\\nvan Dongen, M., Lecoutre, C., & Roussel, O. (2009). 4th international CSP solver competi-\\ntion. Instances and results available at http://www.cril.univ-artois.fr/CPAI09/.\\nWalsh, T. (2000). SAT v CSP. In Principles and Practice of Constraint Programming -\\nCP’00, pp. 441–456.\\nZhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Eﬃcient conﬂict driven\\nlearning in Boolean satisﬁability solver. In International Conference on Computer-\\nAided Design - ICCAD’01, pp. 279–285.\\nZhang, L., & Malik, S. (2002). The quest for eﬃcient Boolean satisﬁability solvers. In\\nComputer Aided Veriﬁcation - CAV’02, pp. 17–36.\\n351\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_list[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def num_tokens_from_doc(shared_list2,doc) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    string=doc.page_content\n",
    "    num_tokens = len(encoding.encode(string, allowed_special={\"<|endoftext|>\"}))\n",
    "    shared_list2.append(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42080"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b879fe4cf94a49039a202b6311c218a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_list2 = manager.list()\n",
    "process_map(partial(num_tokens_from_doc, shared_list2),texts,max_workers=5,chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for a in shared_list2:\n",
    "    cnt+=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5953371000000001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cnt/1000)*0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=10\n",
    "price=0.001\n",
    "with open(\"./b.txt\", 'a') as file:\n",
    "    data = \"%d tokens = %lf\\n\" %(cnt,price)\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=os.path.join('./',\"TokenPrice\")+'.txt'\n",
    "            with open(file_name, 'a') as file:\n",
    "                data = \"%lf\\n\" %(price)\n",
    "                file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import getpass\n",
    "os.environ['OPENAI_API_KEY']=getpass.getpass()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "\n",
    "docsearch = OpenSearchVectorSearch.from_documents(\n",
    "    texts[:5],\n",
    "    embeddings,\n",
    "    opensearch_url=\"https://search-yeondoo-opensearch-2r3sj6ok7iowthxkgjrnhxsyv4.ap-northeast-2.es.amazonaws.com\",\n",
    "    http_auth=(\"admin\", \"qiQduz-pyrhab-hexzo4\"),\n",
    "    use_ssl = False,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    "    index_name=\"allcontent4\",# with metadata source\n",
    "    bulk_size=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1401.4613'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0].metadata['paper_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"./TokenPrice.txt\",'r')\n",
    "f1 = f.readlines()\n",
    "price=0\n",
    "for x in f1:\n",
    "    price+=float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.64080999999999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
